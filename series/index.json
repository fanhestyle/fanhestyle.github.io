[{"content":" 1. 概述 本文完善之前编写的MBR，使用操作显存的方式来输出字符\n2. 实模式下的内存布局 实模式下我们使用的内存是1MB的内存空间，这是从8086继承下来的遗产，基本上我们最后使用的是80386上的特性，由于需要使用这1MB的内存，介绍以下这1MB内存的布局\n3. 操作显存 通过上面的内存布局，我们可以在显存中写入一些数据，这样显存中写入的数据最终会在屏幕上被打印出来，由于我们编写一个简易的操作系统，因此只关心显存中的文本显示区域，也就是内存地址在(0xB8000\u0026ndash;0xBFFF)这段区域\n在显存中写入数据的时候，我们一般是以2个字节为单位。低字节是字符的ASCII码，高字节是字符属性元信息。在高字节中，低4位是字符前景色，高4位是字符的背景色。颜色用RGB红绿蓝三种基色调和，第4位用来控制亮度，若置1则呈高亮，若为0则为一般正常亮度值。第7位用来控制字符是否闪烁（不是背景闪烁）\n4. 编码 有了上述基础，那么就可以不用借助BIOS中断提供的功能来打印字符，而是直接操作显存来打印，代码如下\n.code16 .section .text movw %cs, %ax movw %ax, %ds movw %ax, %es movw %ax, %fs movw $0x7c00, %sp movw $0xb800, %ax movw %ax, %gs //清屏 movw $0x600, %ax movw $0x700, %bx movw $0x0, %cx movw $0x184f, %dx int $0x10 //显存中写入数据 movb $\u0026#39;1\u0026#39;, %gs:0x0 movb $0xA4, %gs:0x1 movb $\u0026#39; \u0026#39;, %gs:0x2 movb $0xA4, %gs:0x3 movb $\u0026#39;M\u0026#39;, %gs:0x4 movb $0xA4, %gs:0x5 movb $\u0026#39;B\u0026#39;, %gs:0x6 movb $0xA4, %gs:0x7 movb $\u0026#39;R\u0026#39;, %gs:0x8 movb $0xA4, %gs:0x9 jmp . .org 510 .word 0xaa55 ","description":"","id":0,"section":"posts","tags":null,"title":"第2课 完善MBR并使用显存","uri":"https://blog.healex.xyz/posts/%E7%AC%AC2%E8%AF%BE-%E5%AE%8C%E5%96%84mbr%E4%BD%BF%E7%94%A8%E6%98%BE%E5%AD%98/"},{"content":" 1. 概述 从本文开始我们正式开始编码的工作，首先是所有学习语言的第一个程序”Hello,World\u0026quot;\n2. MBR简介 主引导记录（Master Boot Record）存放在磁盘的于0盘0道1扇区（扇区从1开始计数，这种标记磁盘的方式称为CHS(即柱面Cylinder磁头Header扇区Sector)表示法，另外还有一种称为LBA逻辑区块地址(Logical Block Address表示法)则是从0开始计数的）\n计算机开机上电之后会进行开机自检，自检的过程实际上是运行BIOS里面程序（BIOS程序是写死在ROM之中的代码），BIOS运行的最后一步是读取磁盘中的MBR扇区内容，并将其拷贝到内存0x7C00的位置，以上过程都是固化写死的，不用我们关心\n操作系统的启动类似于一场接力赛，BIOS选手把第一棒将给我们的MBR，从MBR开始之后就是我们需要关心的内容，于是我们需要首先编写MBR，MBR中的内容是固定的，如下图所示：\n目前我们关心的只有第一项：启动代码，后续在进行磁盘管理方面功能开发的时候需要了解第二项\n3. 编写程序 完整的代码如下\n.code16 .section .text movw %cs, %ax movw %ax, %ds movw %ax, %es movw %ax, %fs movw %ax, %gs movw $0x7c00, %sp /* 清屏利用0x06号功能,上卷全部行,则可清屏 中断号：INT x10　功能号:0x06　功能描述:上卷窗口 输入: AH 功能号= 0x06 AL 上卷行数(如果为0，表示全部) BH 上卷行属性 (CL,CH) = 窗口左上角的(X,Y)位置 (DL,DH) = 窗口右下角的(X,Y)位置 无返回值: */ movw $0x600, %ax movw $0x700, %bx movw $0x0, %cx /*VGA文本模式中,一行只能容纳80个字符,共25行， 下标从0开始,所以0x18=24,0x4f=79,DX=0x184f 左上角(0,0)，右下角(80,25) */ movw $0x184f, %dx int $0x10 //以下3行获取光标位置 movb $0x3, %ah movb $0x0, %bh int $0x10 //以下6行打印字符串 movw $message, %ax movw %ax, %bp movw $MSG_LEN, %cx movw $0x1301, %ax movw $0x2, %bx int $0x10 jmp . message: .ascii \u0026#34;Hello,World!\u0026#34; MSG_LEN = . - message .org 510 .word 0xaa55 代码基本上就是清屏和打印字符串的操作，需要注意的是：\n（1）代码中使用的功能来自于BIOS自带的一些中断处理例程（类似于我们使用的一些库函数调用）\n（2）我们生成的文件必须是纯二进制的文件，并且文件的大小固定是512个字节，这样才能满足MBR的要求\n生成文件的可以使用as和ld两个工具编译和链接，使用ld需要编写ld的脚本，由于本系列使用的链接脚本内容不是关注的重点，在此一笔带过。链接是一个庞大的主题，如果深究下去也可以写一个系列，本系列关注操作系统的编写，链接使用的仅仅是最简单的脚本，如下\nSECTIONS { . = 0x7c00; .text : {*(.text)} } OUTPUT_FORMAT(binary) 脚本的作用是让连接器把文件中的符号起始地址设置在0x7c00处，这样我们在使用BIOS把我们的代码加载到0x7C00处运行时就不会出现错误\n4. 编译并运行 编译我们使用了Makefile的脚本，随着工程的逐步壮大，有必要使用Makefile来组织整个项目，代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  mbr.bin: mbr.o @ld -T mbr.lds -m elf_i386 mbr.o -o mbr.bin mbr.o: mbr.s @as --32 mbr.s -o mbr.o .PHONY:run,clean run: make clean \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make disk \u0026amp;\u0026amp; bochs disk: @bximage -mode=\u0026#34;create\u0026#34; -hd=60M -imgmode=\u0026#34;flat\u0026#34; -q hd60M.img @dd if=mbr.bin of=hd60M.img conv=notrunc clean: @$(RM) -r *.txt *.o *.bin hd60M.img   运行效果如下：\n","description":"","id":1,"section":"posts","tags":null,"title":"第1课 初识MBR程序HelloWorld","uri":"https://blog.healex.xyz/posts/%E7%AC%AC1%E8%AF%BE-%E5%88%9D%E8%AF%86mbr%E7%A8%8B%E5%BA%8Fhelloworld/"},{"content":"1. 概述 本文主要介绍任何搭建开发环境，个人使用的开发环境如下：\n macOS 12.3.1 Monterey Bochs 2.7 Apple clang version 13.0.0 (clang-1300.0.27.3)  2. 搭建开发环境   安装必要的开发工具集\n在MacOS中打开终端，终端中键入gcc，弹出提示框让我们安装开发组件，直接点下载安装即可\n  安装Homebrew\n我个人直接使用brew来安装Bochs，因此需要首先安装Homebrew，直接去Homebrew的官网贴一行代码到终端即可安装完成\n  安装bochs\n一个命令搞定\nbrew install bochs 3. Bochs环境配置 Bochs安装好之后类似于一台虚拟的电脑已经组装好，但是要启动它还需要进行一些配置（相当于给电脑设置一些硬件参数），Bochs读取这个配置文件的顺序如下：\n  1. .bochsrc in the current directory 2. bochsrc in the current directory 3. bochsrc.txt in the current directory 4. (win32 only) bochsrc.bxrc in the current directory 5. (Unix only) .bochsrc in the user\u0026#39;s home directory 6. (Unix only) bochsrc in the /etc directory 首先查看brew将bochs安装的目录\nbrew list bochs 输出如下：\n/usr/local/Cellar/bochs/2.7/bin/bochs /usr/local/Cellar/bochs/2.7/bin/bximage /usr/local/Cellar/bochs/2.7/lib/bochs/ (117 files) /usr/local/Cellar/bochs/2.7/share/bochs/ (30 files) /usr/local/Cellar/bochs/2.7/share/doc/ (8 files) /usr/local/Cellar/bochs/2.7/share/man/ (4 files) 我们可以直接在运行目录下面添加一个bochsrc的文件，文件内容如下：\n第一步，首先设置 Bochs 在运行过程中能够使用的内存，本例为 32MB megs: 32 #第二步，设置对应真实机器的 BIOS 和 VGA BIOS romimage: file=/usr/local/Cellar/bochs/2.7/share/bochs/BIOS-bochs-latest vgaromimage: file=/usr/local/Cellar/bochs/2.7/share/bochs/VGABIOS-lgpl-latest #第三步，设置 Bochs 所使用的磁盘，软盘的关键字为 floppy。 #若只有一个软盘，则使用 floppya 即可，若有多个，则为 floppya，floppyb… #floppya: 1_44=a.img, status=inserted #第四步，选择启动盘符 #boot: floppy #默认从软盘启动，将其注释 boot: disk #改为从硬盘启动。我们的任何代码都将直接写在硬盘上，所以不会再有读写软盘的操作 #第五步，设置日志文件的输出 log: bochsout.txt #第六步，开启或关闭某些功能 #下面是关闭鼠标，并打开键盘 mouse: enabled=0 #keyboard_mapping: enabled=1, map=/usr/share/bochs/keymaps/x11-pc-us.map keyboard: keymap=/usr/local/Cellar/bochs/2.7/share/bochs/keymaps/sdl2-pc-us.map # 硬盘设置 ata0: enabled=1, ioaddr1=0x1f0, ioaddr2=0x3f0, irq=14 ata0-master: type=disk, path=\u0026#34;hd60M.img\u0026#34;, mode=flat, cylinders=121, heads=16, spt=63 # 如果编译bochs的时候带了-gdbstub选项才能开启，这样就可以使用gdb联合bochs调试 # 在bochs中支持2种调试方式：(1)bochs自己带的调试器 (2)gdb远程调试bochs #gdbstub: enabled=1, port=1234, text_base=0, data_base=0, bss_base=0 display_library: sdl2 相比Linux下的配置有两个地方有差异：\n（1）display_library: sdl2 在Linux下使用的是x11的显示库\n（2）keyboard: keymap的配置使用的是sdl2-pc-us.map，而不是x11的map\n4. 编写Makefile 为了测试环境编写一个简单的Makefile文件，目前暂时没有生成目标，运行只需要输入\nmake run 即可启动\nMakefile文件如下：\n1 2 3 4 5 6 7 8 9 10  .PHONY:run,clean run: make clean \u0026amp;\u0026amp; make disk \u0026amp;\u0026amp; bochs disk: @bximage -func=\u0026#34;create\u0026#34; -hd=60M -imgmode=\u0026#34;flat\u0026#34; -sectsize=512 -q hd60M.img clean: @$(RM) -r *.txt *.o *.bin hd60M.img   备注：不同版本的bochs提供的bximage工具的参数有比较大的差异，具体使用方式请man bximage 查阅\n","description":"","id":2,"section":"posts","tags":null,"title":"第0课 开发环境搭建","uri":"https://blog.healex.xyz/posts/%E7%AC%AC0%E8%AF%BE-%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"content":"1. 简介 快速排序是一种使用非常广泛并且高效的排序算法，它和归并排序（Merge Sort）类似，一般也是采用递归的方式来实现，它们都是分治算法(Divide-and-Conquer)算法的一些典型的应用\n2. 算法思路 快速排序的算法思路如下：\n对于一个无序的数组，我们要将其按从小到大的顺序排列，过程如下：\n 如果数组元素是1，那么直接返回 从数组中挑选一个元素，一般称之为Pivot，以它为界，把小的元素都放在左侧，大的元素放在Pivot值的右侧 这样数组被分成了三部分：小于pivot值 等于pivot值 大于pivot值，我们分别用集合S1，S2，S3代替，很显然合并S1-S2-S3就是最终排好序的结果 递归的对S1和S3进行快速排序操作  3. 算法实现 3.1 我个人的实现与分析 快速排序的算法思想比较简单，在看过一篇文章就理解了，但是在实作层面，发现有非常多的细节需要处理，稍不留意就会导致数组越界或者是死循环的情况，本文再回头对这个算法进行全面的手术刀式的分析，以期望对算法的每一个细节完全理解透彻。\n原始的代码：\ntemplate\u0026lt;typename T\u0026gt; void QuickSort_Impl(T arr[], int beg, int end) { if (beg \u0026gt;= end) return; T pivot = arr[beg]; int i = beg; int j = end; while (i \u0026lt;= j) i while (arr[i] \u0026lt;= pivot) { i++; } while (arr[j] \u0026gt;= pivot) { j--; } std::swap(arr[i], arr[j]); } QuickSort_Impl(arr, beg, i - 1); QuickSort_Impl(arr, i + 1, end); } template\u0026lt;typename T\u0026gt; void quickSort(T arr[], int n) { QuickSort_Impl(arr, 0, n - 1); } 先了解一下写算法时候的思路： 每次选取待排序数组的第一个元素值作为pivot，尝试将待排序数组中的元素以pivot值为界分为左右两侧，左侧的元素都小于或等于pivot，右侧的元素都大于或者等于pivot，在进行处理的时候，选取了下标i和j分别指向数组的开头与结尾的索引值。i从前往后递增（如果arr[i] \u0026lt;= pivot），j从后往前递减（如果arr[j] \u0026gt;= pivot），如果i卡在一个大于pivot的元素处，同时j卡在一个小于pivot的元素处，那么我们交换arr[i]和arr[j]的值，这样可以把i位置的元素变成小于pivot的，j位置的元素变成大于pivot的，这样i和j又可以继续朝指定方向前进，直到i超过了j或者i和j在同一个位置，说明已经遍历完了整个数组，把数组的元素分好类了。因为i位置的元素是pivot，那么pivot是排好序的位置，接着递归的对pivot左侧和pivot右侧的子数组再进行排序，直到整个排序结束，就完成了整个算法。\n 问题1 数组的越界问题  \twhile (arr[i] \u0026lt;= pivot) { i++; } while (arr[j] \u0026gt;= pivot) { j--; } 这两个循环有可能会造成数组越界，外层的 while(i\u0026lt;=j) 是在一开始进行的判断，无法约束i和j一直递增或者递减的情况。假设整个数组arr[0]是最小值，那么在第一次选pivot的时候是arr[0]，j这个变量就会越界，因为所有的元素都比pivot大（或者等），于是j就直接变成-1了，很显然是错误的。所以我们要做的第一处修改就是约束 i 和 j 变量的取值\n我们直到如果i和j相等实际上就说明已经通过i和j遍历完了整个数组了，于是判断条件是 i \u0026lt; j\n于是代码变为：\n\twhile (i \u0026lt;= j) { while (i \u0026lt; j \u0026amp;\u0026amp; arr[i] \u0026lt;= pivot) { i++; } while (i \u0026lt; j \u0026amp;\u0026amp; arr[j] \u0026gt;= pivot) { j--; } std::swap(arr[i], arr[j]); } 这样还是有一个问题，当i和j相等之后，两个内层循环进不去，一个swap语句在交换两个相等的数，并且外层的while循环一直是true，这样就进入死循环了，于是while进入的条件应该不能包括i和j相等的情况，所以外层的while循环也应该修改为while(i \u0026lt; j)\n\twhile (i \u0026lt; j) { while (i \u0026lt; j \u0026amp;\u0026amp; arr[i] \u0026lt;= pivot) { i++; } while (i \u0026lt; j \u0026amp;\u0026amp; arr[j] \u0026gt;= pivot) { j--; } std::swap(arr[i], arr[j]); }  问题2 数组pivot分界的问题  在调试之后我发现数组根本每一次都没有在pivot的位置进行分界，也就是说我们期望数组在每一次找到pivot位置的时候，分成左右两侧，左侧小于pivot，右侧大约pivot（也就是数组的值如果小于pivot，那么它们的索引号一定也小于pivot），由于我们判断中arr[i] \u0026lt;= pivot的缘故，导致我们会越过pivot，也就是说最后循环退出的时候，i的位置上元素根本就不是pivot值，这样就起不到分块的作用了，于是代码修改为： arr[i] \u0026lt; pivot，把相等的条件去掉，于是代码修改为：\nwhile(i \u0026lt; j \u0026amp;\u0026amp; arr[i] \u0026lt; pivot)  问题3 递归调用的范围问题  当我们把条件修改成为 arr[i] \u0026lt; pivot 之后，伴随而来又有一个问题，如果数组的第一个元素是最小的，在第一次运行QuickSort_Impl时，我们的i就不会移动，导致退出while循环的时候i的取值是0，这样就没有办法调用 QuickSort_Impl(arr, beg, i - 1); 因为会产生一个-1的索引\n另外如果数组的第一个元素是最大的，会导致j不会移动，当进行一次swap之后，最大的元素被移动到了数组最后的位置，这时候i会一直向后移动，直到i移动到j的位置（i==j）并且是移动到数组的最后一个位置，此时 while (i \u0026lt; j \u0026amp;\u0026amp; arr[j] \u0026gt;= pivot) 这个循环不会被执行，最后进行一次swap(pivot,pivot)的操作，退出循环时候 i的取值是最大的（数组的最大索引号），这样就造成一个问题，最后一个分片的起始位置就越界了 QuickSort_Impl(arr, i + 1, end); 因为产生一个数组元素个数的索引（数组最大索引应该是size-1)\n我们直到出现这两种情况的时候，数组其实只有一个元素，也就是说就是排好序的了，于是我们在递归中加上一个判断\n\tif (i \u0026gt; beg) QuickSort_Impl(arr, beg, i - 1); if (i \u0026lt; end) QuickSort_Impl(arr, i + 1, end);  问题4 pivot值的处理  尽管已经按照上面的方式改动了大量的代码，但还是有问题，比如下面这个测试用例： [6,8,7,5]\n这种情况就比较麻烦了，也就是说这个pivot值要十分小心的进行处理，可以想到的处理方式如下：\n 选定最开始的元素作为pivot之后，执行一次swap，把最开始的元素和结尾的元素进行一次交换 j的位置从倒数第二个元素开始（因为最后一个元素是交换过去的pivot） 最终确定好pivot应有的位置之后，把i所在的位置和数组最末尾的元素交换回来  按照这种想法改进如下：\ntemplate\u0026lt;typename T\u0026gt; void QuickSort_Impl(T*\u0026amp; arr, int beg, int end) { if (beg \u0026gt;= end) return; T pivot = arr[beg]; std::swap(arr[beg], arr[end]); int i = beg; int j = end - 1; while (i \u0026lt; j) { while (i \u0026lt; j \u0026amp;\u0026amp; arr[i] \u0026lt; pivot) { i++; } while (i \u0026lt; j \u0026amp;\u0026amp; arr[j] \u0026gt;= pivot) { j--; } std::swap(arr[i], arr[j]); } std::swap(arr[i], arr[end]); if (i \u0026gt; beg) QuickSort_Impl(arr, beg, i - 1); if (i \u0026lt; end) QuickSort_Impl(arr, i + 1, end); } 经过测试发现在只有两个元素时，这种情况下会出错。比如数组是 [2,1]时，排序结果是 [2,1]，为了处理这种情况，只需要对最后 pivot和arr[i]做一个判断即可，加上条件 if (arr[i] \u0026gt; arr[end])\n最终的快速排序的完整代码如下：\n#include \u0026lt;algorithm\u0026gt; template\u0026lt;typename T\u0026gt; void QuickSort_Impl(T*\u0026amp; arr, int beg, int end) { if (beg \u0026gt;= end) return; T pivot = arr[beg]; std::swap(arr[beg], arr[end]); int i = beg; int j = end - 1; while (i \u0026lt; j) { while (i \u0026lt; j \u0026amp;\u0026amp; arr[i] \u0026lt; pivot) { i++; } while (i \u0026lt; j \u0026amp;\u0026amp; arr[j] \u0026gt;= pivot) { j--; } std::swap(arr[i], arr[j]); } if (arr[i] \u0026gt; arr[end]) std::swap(arr[i], arr[end]); if (i \u0026gt; beg) QuickSort_Impl(arr, beg, i - 1); if (i \u0026lt; end) QuickSort_Impl(arr, i + 1, end); } template\u0026lt;typename T\u0026gt; void quickSort(T arr[], int n) { QuickSort_Impl(arr, 0, n - 1); } 这个快速排序从我看完算法描述到写出完整代码调试边界情况，整整花费了一个下午的时间，这也充分说明了理解和最终实作落到代码层面是两个完全不同的事情，平常还是需要多写。数据结构不能仅仅停留在理论上理解了，一定要落在纸上，真正的写一个可以运行的实现。\n3.2 网络上另一种实现思路(参考资料2) 4. 更好的快速排序实现(wiss参考资料1) 参考资料  书籍：Data Structures and Algorithm Analysis in C++ (Fourth Edition), by Mark Allen Weiss 7.7节-快速排序\n2. 2.8.1 QuickSort Algorithm\n3.Quicksort  ","description":"","id":3,"section":"posts","tags":null,"title":"排序算法之快速排序(QuickSort)","uri":"https://blog.healex.xyz/posts/quick_sort/"},{"content":"1. 简介 堆排序使用到了堆（优先队列）的性质，假设一个堆是小顶堆，那么最大的元素在堆顶的位置，堆排序的步骤包括两个：\n 创建堆结构 依次移除堆顶的元素，移除的元素存放在数组中  从上面的描述我们可以大概的直到，堆排序需要一个额外的数组来存储排好序的队列，接着再把排好序的数组复制回原来的数组\n2. 预备知识 首先了解以下堆的特性，堆和二叉排序树不同，它并没有左右子树的约束关系，而仅仅是有一个树根和左右子树的约束关系（树根的元素一定的最小的，假设针对的是小顶堆），并且使用数组实现的堆有一些特别的特性。\n在讨论特性时，我们需要了解一下堆这种数据结构的实现（假设底层采用的是数组的实现），在我遇到的代码中有基于索引1开始的实现（也就是把数组索引为0的位置空出来，另作他用），也有使用索引位置为0开始的实现，它们的区别如下：\n 根节点索引为0 根节点索引为1 左孩子(数组下标) (index * 2 + 1) (index * 2) 右孩子(数组下标) (index * 2 + 2) (index*2 + 1) 父节点(数组下标) (index - 1) / 2 (index/2) 也就是说采用索引0或者1开始其实无关紧要（但是也有人争议说采用*2 /2可以通过移位快速实现，也有人反驳提到 *2 /2 的移位实现在当今的硬件上和 +1 +2几乎误差，具体见参考资料2）\n3. 实现 在堆排序实现时，需要注意2点：\n  按照之前的讨论，感觉上我们应该需要额外的一个数组空间来存储排好序的结果，但是事实上我们可以复用之前的数组，因为当数组deleteRoot之后，整个堆实际上少一个元素，我们可以把删除的元素存储在空出的数组里面，但是这样做会带来一个问题，最后得到的结果时逆序的，因此为了可以正常排序，我们需要建立的堆和我们排序的情况相反的堆，也就是当要从小到大排列的时候，我们需要创建大顶堆；当需要从大到小的情况排列时，我们需要创建小顶堆。\n  堆排序不要尝试去创建一个堆数据结构，也就是说当使用C++去实现的时候，不要创建一个堆的类，这样代码太复杂了，而仅仅是创建堆序就好了，代码比较轻量级一点。\n  3.1 自底向上的构建堆的方法 实现的伪代码如下：\n堆排序包括两个步骤（1）创建堆（2）移除堆顶元素 直至整个堆元素处理完\n HeapSort算法  heapsort(a, count) input: 长度为count乱序的数组 heapify(a, count) //首先创建堆 //在处理过程中使用变量end记录堆结束的位置（a[0:end]标识堆区域） // a[end:count-1]是已经拍好的排好序的元素数组 end = count - 1 //用 end 记录堆中排好序和属于堆的元素 while end \u0026gt; 0 do swap(a[end],a[0]) //交换end和a[0]，把最大的元素移除 end = end - 1 //end前移1，标识最大的元素被删除出堆，进入排好序的子列 siftDown(a,0,end) //a[0]根节点位置被移除，堆性质被破坏，重新整理堆 可以从上面的伪代码看出，堆排序需要两个子函数 heapify（创建堆）和 siftDown（在堆的性质破坏之后恢复堆的性质）\n 子函数 heapify  procedure heapify(a, count)\nstart = iParent(count-1) //找到最后一个元素的父节点索引号\nwhile start \u0026gt;=0 do siftDown(a, start, count-1) start = start - 1   子函数 siftDown(a, start, end)  procedure siftDown(a, start, end)\nroot = start while iLeftChild(root) \u0026lt;= end do child = iLeftChild(root) nextPos = root if a[nextPos] \u0026lt; a[child] then nextPos = child if child+1 \u0026lt;= end and a[nextPos] \u0026lt; a[child+1] then nextPos = child + 1 if nextPos = root then return else swap(a[root], a[nextPos]) root = nextPos;  以下是堆排序的C++实现代码(我个人手写的，可能还需要优化)\nint parent(int childIndex) { return (childIndex - 1) / 2; } int leftChild(int parentIndex) { return (2 * parentIndex + 1); } //从pos位置节点开始下沉直到处理到叶节点 //arr:数组指针 //pos:当前调整的节点索引号（是一个子树的根节点的索引号） //n：当前堆的元素总数 template\u0026lt;typename T\u0026gt; void siftDown(T arr[], int pos, int n) { int leftChildIndex = leftChild(pos); while (leftChildIndex \u0026lt; n) { //记录我们把根节点元素移动到的下一个位置 //下一个位置有可能是左孩子或者右孩子（如果存在右孩子的话） //如果下一个节点位置通过比较根节点和左右孩子节点的值发现不需要 //移动的话，说明我们根节点的值就应该保持原地不动，也就是说已经完成了 int nextTravsalIndex = pos; if (arr[nextTravsalIndex] \u0026lt; arr[leftChildIndex]) { nextTravsalIndex = leftChildIndex; } //如果节点有右节点,并且右节点的值大于（左节点和根节点值中的较大者） if (leftChildIndex + 1 \u0026lt; n) { if (arr[nextTravsalIndex] \u0026lt; arr[leftChildIndex + 1]) { nextTravsalIndex = leftChildIndex + 1; } } //我们把根节点上的元素往下沉，但是判断左右孩子都不大于这个根节点的数， //说明当前根节点的元素位置是符合堆性质的 if (nextTravsalIndex == pos) return; std::swap(arr[nextTravsalIndex], arr[pos]); pos = nextTravsalIndex; leftChildIndex = leftChild(nextTravsalIndex); } } template\u0026lt;typename T\u0026gt; void heapify(T arr[], int n) { if (n \u0026lt;= 1) return; //从最后一个节点的父节点开始，依次减少到根节点，将每一棵子树都调整为大顶堆 for (int i = parent(n-1); i \u0026gt;= 0; i--) { siftDown(arr, i, n - 1); } } template\u0026lt;typename T\u0026gt; void heapSort(T arr[], int n) { if (n \u0026lt;= 0) return; heapify(arr, n); while (n \u0026gt; 0) { std::swap(arr[0], arr[n - 1]); n--; siftDown(arr, 0, n); } } 3.1.2 补充：递归构造下沉 在下沉的时候，可以使用迭代亦可使用递归的做法，上文中给出的是迭代的代码，此处补充一下递归下沉的代码：\n/* recursive version of siftDown 具体见参考资料4 */ template\u0026lt;typename T\u0026gt; void siftDown_recursive(T arr[], int pos, int n) { //递归退出的出口 if (pos \u0026gt; n) return; int leftChildIndex = leftChild(pos); int rightChildIndex = leftChildIndex + 1; T leftValue = arr[leftChildIndex]; int maxValueIndex = pos; if (leftChildIndex \u0026lt; n \u0026amp;\u0026amp; arr[pos] \u0026lt; arr[leftChildIndex]) maxValueIndex = leftChildIndex; if (rightChildIndex \u0026lt; n \u0026amp;\u0026amp; arr[maxValueIndex] \u0026lt; arr[rightChildIndex]) maxValueIndex = rightChildIndex; if (maxValueIndex == pos) { return; } else { std::swap(arr[pos], arr[maxValueIndex]); siftDown(arr,maxValueIndex,n); } } 3.1.3 补充：延伸阅读：见参考资料1，里面有提及一种叫”heapsort with bounce“的优化方式，我暂时没看明白，不理解它的优化点在何处，后续继续研究 3.2 自顶向下构造堆的方法 在上述的3.1中介绍的方法，创建堆的方法是从最后一个节点的父节点开始，依次往上去构造堆的方法进行的，这种做法有些tricky，可能第一时间不太容易想到，比较直观的一种做法是直接从乱序的数组第一个元素开始构造堆，这种方式应该最容易想到的做法，我们来尝试一下。\n伪代码如下：\nprocedure heapify(a, count) end = 1 //end从第一个左孩子开始（根的左孩子，根的索引是0） while end \u0026lt; count siftUp(a,0,end) end = end + 1 procedure siftUp(a, start, end) child = end while child \u0026gt; start parent = iParent(child) //计算parent的索引号 if a[parent] \u0026lt; a[child] then swap(a[parent], a[child]) child = parent else return siftUp实现的堆不能像siftDown那样，在交换元素之后可以进行“堆的修复”，** siftUp这种方式实现的堆必须每次移除元素后都重建整个堆 **\nprocedure heapsort(a, count) heapify(a,count) end = count - 1 while end \u0026gt; 0 do swap(a[end],a[0]) heapify(a,end) end = end - 1 这种方式实现的C++代码如下所示：（我手写的代码，大量使用了递归）\ntemplate\u0026lt;typename T\u0026gt; void siftUp(T arr[], int index, int n) { int parentIndex = parent(index); if (parentIndex \u0026gt;= 0 \u0026amp;\u0026amp; arr[index] \u0026gt; arr[parentIndex]) { std::swap(arr[index], arr[parentIndex]); siftUp(arr,parentIndex,n); } } template\u0026lt;typename T\u0026gt; void heapify(T arr[], int n) { for (int i = 1; i \u0026lt; n; i++) { siftUp(arr, i, n); } } template\u0026lt;typename T\u0026gt; void heapSort(T arr[], int n) { if (n \u0026lt;= 1) return; heapify(arr, n); std::swap(arr[0], arr[n - 1]); heapSort(arr, n-1); } 3.3 两种思路的比较和算法复杂度分析 3.1 的思路有点类似于从最底下的非叶节点开始，逐步向根移动，并且每次都“修补”好堆的结构\n3.2 的思路是从空的堆开始，逐步构建一个完整的堆，它是从最上面的根的子节点开始的\n需要根据算法中描述的具体操作步骤才能分析清楚这两者的特点：\n3.1 具体来说是一种“ bottom up scan , and perform a sift-down” 也就是从整体来说是 “从下往上”，但是局部确是“从上往下”\n3.2 具体来说是一种“ top down scan, and perform a sift-up\u0026quot;，从整体来说是”从上往下“，但是局部确实”从下往上“\nHeapify的时间复杂度：\n3.1 这种方式时间复杂度是O(N)\n3.2 这种方式时间复杂度是O(NlogN)\n但是两者实现的HeapSort的时间复杂度都是O(NlogN)，一般来说大家普遍实现的堆排序的算法是3.1中这种方式\n在通过数组构建堆的时候，从数组的第一个位置开始依次向后，a[0]\u0026ndash;\u0026gt;a[n-1] 这种方式称之为 sift-up的方式（从外在形式上看其实是Top-Down的方式，但是这里的sift-up指的是插入的每一步操作的方式，是将节点依次往上浮），从0开始创建一个堆；\n在通过数组构建堆的时候，从数组的最后一个位置开始依次向前，a[n-1]\u0026ndash;\u0026gt;a[0] 这种方式称之为 sift-down的方式（从外在形式上看其实是Bottom-Up的方式，但是sift-bottom指的是每一次操作一个元素采用的方式，是把节点往下沉），类似于修补一个损坏的堆\n可以通过下面的事实了解到一些复杂度区别的本质：\n 往上浮的代价是节点距离根节点的距离 往下沉的代价是节点距离叶子节点的距离  很明显由于堆是完全二叉树，叶节点的节点数量明显比非叶节点多不少，于是从感性上就可以认识到往上浮肯定没有往下沉好。因为往上浮叶节点的操作代价最高，而有大量的叶节点，而往下沉根节点的代价最高，但是根节点只有一个而已。\n另外这两种思路最后获得的堆结构可能是不同的，但是最终都能得到正确的排序结果。\n更多的内容见参考资料部分\n5. 参考资料 1. Wiki: Heapsort\n2. Why in a heap implemented by array the index 0 is left unused?\n3. Weiss :Data Structures and Algorithm Analysis in C++ (Fourth Edition) Chapter 7.5 Heap Sort\n4. 堆排序(Heapsort)\n5.siftUp and siftDown operation in heap for heapifying an array\n6.How can building a heap be O(n) time complexity?\n","description":"","id":4,"section":"posts","tags":null,"title":"排序算法之堆排序","uri":"https://blog.healex.xyz/posts/heap_sort/"},{"content":"1. 简介 希尔排序是希尔(Donald Shell)于1959年提出的一种排序算法，它是插入排序的一种改进算法，在插入排序中，我们每一次比较的是待插入数和已排好序的子数组。这样在插入的时候每一次进行相邻间元素的一次交换，希尔排序则不一样，它每次排序以一个固定的间隔进行（这个间隔被称为gap），并且最后一次的gap一定是1（也就是最后一次的排序是一次普通的插入排序）\n为什么要如此设计呢？我们考虑这样一个情形，比如下述的待排序数组\n[5,3,7,4,8,9,6,2,1]\n当我们插入排序的时候，在最后两个元素2和1进行排序的时候，我们会发现需要大量的移动操作才能把2和1放到它们应有的位置（也就是数组的开头），这样就会萌生一个想法，能不能尽快的使得2和1这样的数迅速的移动到前面呢？而不用每次一个一个数的比较前移。Shell排序就是这种想法，它用非1的间隔来进行比较，假设我们用4的间隔进行比较，在第一趟中元素4和2比较，发现2在后面，会把2移到元素4的位置，这样元素2一下子就能往前走好多步。并且当我们缩小间隔gap的时候，之前比较大间隔拍好的序列不会白费（也就是之后减少间隔的排序还是会保留之前排序的成功，相当于前人做的努力没有白费，成果一直保留在那儿），直到gap是1的最后一次排序操作，最后一次的gap为1的排序一定能保证整个数组排好序（因为它就是一次简单的插入排序嘛），而可以预期最后一次的排序需要移动的元素一定不会太多。\n另外参考资料2中给出了一个解释（也是数据结构与算法分析这本书提及的），我们把数组中逆序的数对找出来，比如上面我们举例的数组中逆序的数对包括（5，3）（5，4）（5，2）（5，1）（3，2）（3，1）\u0026hellip; 这些数对期望的对数是 $$ \\frac {n(n-1)} 4 $$ ，如果我们采取的是逐个比较相邻两个数，通过相邻两个数来决定调整相邻两个数之间的位置，这样我们一次操作最多能纠正一对逆序的数对，也就是说像插入排序、冒泡排序、选择排序这种每次只通过比较相邻的元素而进行交换的排序算法，它们的时间复杂度一定是 $$ O(n^2) $$，那么怎样提高这个排序效率呢？\n关键点就是我们不能一直比较相邻的数，而应该比较相距较远的数，这样有可能在一次交换之后能够期望达到纠正超过一个逆序对的效果，可是有人又会问：如果一次相聚较远的数，那会不会导致交换的数对中增加了额外的逆序数呢？下面我们来证明通过交换间隔较远的数对不会造成逆序数的增加。\n假设有位置i和j，i \u0026lt; j，但是a[i] \u0026gt; a[j]，我们假设数组排好序之后是从小到大排列，很显然（i，j）是一个逆序对，我们想知道交换i，j会不会造成逆序对的增加，因为i和j的交换会影响到i和j之间的数（i和j之前和之后的数和i、j的相对关系不变，因此不会影响），考虑到i和j之间的任意一个数，假设是k（i \u0026lt; k \u0026lt; j)，我们讨论下列几种情况：\n a[k] \u0026gt; a[i] a[k] \u0026lt; a[j] a[i] \u0026lt; a[k] \u0026lt; a[j]  也就是说a[k]的值小于最小的，位于最小和最大之间以及大于最大的，这样就完全覆盖了a[k]的取值情况，这样我们来分析它们交换之后的效果：（我们用1，2，3来标识a[i] a[k] a[j]这样的值）\n 情况1：初始是 2 3 1 ，交换i和j之后变为 1 3 2，逆序对从2变为1 情况2：初始是 3 1 2 ，交换i和j之后变为 2 1 3，逆序对从2变为1 情况3：初始是 3 2 1，交换i和j之后变为 1 2 3，逆序对从3变为0  于是我们可以说当使用间隔较大的数对交换时，一定是会减少逆序数的，有可能减少一对，也有可能减少多对，这样就至少比每次减少一对的算法要好，虽然我们不知道好的上限是好到多少，但是至少不比插入、冒泡、选择这些排序效果要差。\n事实上希尔排序的时间复杂度的证明相当的复杂，需要使用数论等非常高级的数学理论来证明，我个人还没有这个能力提供这些证明，看懂也暂时不可能，记住这个思想和为什么比普通的二次排序要好对于非理论研究的开发者来说要应该是足矣。\n2. 实现 希尔排序的实现不是特别的复杂，以下的实现包括我个人初次学习写下的一些代码\n2.1 我个人的代码 template\u0026lt;typename T\u0026gt; void shellSort(T arr[], int n) { for (int gap = n / 2; gap \u0026gt;= 1; gap /= 2) { for (int i = 0; i \u0026lt; n; i++) { for (int j = i+gap; j \u0026lt; n; j += gap) { int k = j; T tmp = arr[k]; for (; k \u0026gt;= gap \u0026amp;\u0026amp; arr[k] \u0026lt; arr[k - gap]; k -= gap) { arr[k] = arr[k - gap]; } arr[k] = tmp; } } } } 我给出的程序也是可以正确得到排序结果的，但是通过和其他标准Shell写法的程序相对比，发现了我给出来的程序会做一些额外无用的操作，从代码一眼就能看出来我写的代码有多层的循环，事实上我在阅读Shell排序的说明之后，第一时间写出来的就是上面的代码，我写的代码中第3层的循环 for(int j=i+gap; j\u0026lt;n; j+=gap) 想法是把所有间隔为gap的所有元素都找出来，然后进行一次常规的插入排序，从思路上来说是没错，但是确有点冗余，比如下面的数列\n[3,7,2,8,1,9,6,5,4] 当遍历到1时，代码会找出来子序列 [3,1,4]，然后用插入排序把所有的数排好，下次遍历到1时，还是会找出来[1,4]又再排一次，这样很明显是有重复操作的。\n问题的关键在于：shell排序是会每次比较子序列，但却不是向我这样生硬的把所有子序列都找出来排一遍。而是逐个元素遍历，找到一个元素之后和之前的相隔gap的元素进行比较，在一次最外层循环之后，每个内层的循环把新的数添加到以前遍历的都是相隔gap位置的子序列中，最终完成排序。\n2.1 Shell给出的实现 希尔最早给出的实现是选取gap的值为 $$ \\lfloor \\frac {N} {2^k} \\rfloor $$ ,实现的伪码如下：\n# Start with the largest gap and work down to a gap of 1 foreach (gap in gaps) { # Do a gapped insertion sort for this gap size. # The first gap elements a[0..gap-1] are already in gapped order # keep adding one more element until the entire array is gap sorted for (i = gap; i \u0026lt; n; i += 1) { # add a[i] to the elements that have been gap sorted # save a[i] in temp and make a hole at position i temp = a[i] # shift earlier gap-sorted elements up until the correct location for a[i] is found for (j = i; j \u0026gt;= gap and a[j - gap] \u0026gt; temp; j -= gap) { a[j] = a[j - gap] } # put temp (the original a[i]) in its correct location a[j] = temp } } C++代码实现如下：\ntemplate\u0026lt;typename T\u0026gt; void shellSort(T arr[], int n) { for (int gap = n / 2; gap \u0026gt;= 1; gap /= 2) { for (int i = gap; i \u0026lt; n; i++) { T tmp = arr[i]; int j = i; for (; j \u0026gt;= gap \u0026amp;\u0026amp; tmp \u0026lt; arr[j - gap]; j -= gap) { arr[j] = arr[j - gap]; } arr[j] = tmp; } } } 3. 时间复杂度分析 Shell排序的时间复杂度非常的繁琐，需要大量的高等数学的知识，我暂时还没能力读懂这些证明（毕竟不是数学相关专业，也对这些内容不感兴趣），因此贴一张别人论证的结论在此\n图中也给出了一些相对表现较好的gap的取值（如果gap是递增方式的，那么我们在编码时只需要找到一个比数组长度小的最大的数，逆序直到1，作为我们的gap序列即可）\n4. 参考资料 1. WiKi:Shellsort\n2.希尔排序为什么会那么牛那么快，能够证明吗？\n3.Mark Allen Weiss:Data Structures and Algorithm Analysis in C++ (Fourth Edition) 7.4 ShellSort\n","description":"","id":5,"section":"posts","tags":null,"title":"排序算法之希尔排序(ShellSort)","uri":"https://blog.healex.xyz/posts/shell_sort/"},{"content":"1. 概述 插入排序是一种相对简单的排序算法，插入排序算法在处理过程中每次处理一个待插入的元素，将它和已经排好序的子序列进行合并成新的已排好序的部分，逐渐增长直到整个数组排序完成。\n插入排序的主要优点包括：\n 实现相对简单（相比较快速排序，堆排序，归并排序来说它的代码相对较少） 对元素不太多的序列有比较好的性能 相比较其他 $ O(n^2) $ 的算法来说更加高效 算法是排序稳定的（值相等的元素位置顺序保持不变） In-place算法，只需要固定的内存空间占用（基本上只需要原先数组的空间即可） Online算法，可以来一个元素处理一个  2. 实现方式 插入排序的算法虽然简单，但是还是有一些细节需要注意，以下列举一些实现\n2.1 我最初的实现 以下是我自己在阅读插入排序描述之后给出的代码：(C++代码)\n 版本1  template\u0026lt;typename T\u0026gt; void insertionSort(T array[], int n) { for (int i = 1; i \u0026lt; n; i++) { int insertPos = 0; T tmp = array[i]; for (int j = 0; j \u0026lt; i; j++) { if (array[j] \u0026lt; tmp) { insertPos++; } } for (int k = i; k \u0026gt; insertPos; --k) { array[k] = array[k - 1]; } array[insertPos] = tmp; } }  版本2  template\u0026lt;typename T\u0026gt; void insertionSort(T array[], int n) { for (int i = 1; i \u0026lt; n; i++) { int insertPos = 0; T tmp = array[i]; for (int j = 0; j \u0026lt;= i; j++) { if (array[j] \u0026lt; tmp) { insertPos++; } } for (int k = i; k \u0026gt; insertPos; --k) { array[k] = array[k - 1]; } array[insertPos] = tmp; } } 以上给出的两个版本的代码，我自己通过测试程序进行测试，测试程序如下：\nint main() { int arr[] = { 1,9,2,6,4,3,8,7,5 }; insertionSort(arr, sizeof(arr) / sizeof(arr[0])); for (auto i : arr) { std::cout \u0026lt;\u0026lt; i \u0026lt;\u0026lt; std::endl; } } 分析我个人写的代码，发现有一些需要改进的点：\n  算法2实际上是有问题的\n使用测试程序是看不出来的，最后给出的结果都是1-9的顺序输出，但是算法2会造成算法的不稳定（也就是会把相等的元素的先后顺序改变）\n  算法1是正确的，但是先找位置，再移动元素可以改进一下，可以从排好序的子序列的最后位置开始往前找，而不是像我写的代码这样从前往后找。因为从后往前有一个好处是交换操作可以边找边做，而从前往后找，再找到位置之后也需要移动元素，何不一边找一边移动呢？其实这也是标准的插入排序的算法实现\n  2.2 常见的插入排序算法实现 以下是一种插入排序的算法伪码实现\ni ← 1 while i \u0026lt; length(A) j ← i while j \u0026gt; 0 and A[j-1] \u0026gt; A[j] swap A[j] and A[j-1] j ← j - 1 end while i ← i + 1 end while 这个算法有几个细节需要注意：\n  while j \u0026gt; 0 and A[j-1] \u0026gt; A[j] 的And 操作必须是一个短路的and操作（类似于C/C++中的 \u0026amp;\u0026amp;，当第一个条件失效时，不会计算第二个条件）\n  这个算法插入的时候，从插入点开始每次都进行了元素的交换\n  进行元素的交换有一个好处是完全不需要额外的空间排序，也就是说算法整个运行过程中仅仅需要算法原始元素的存储空间。不过过多的交换或许并不是很合适，可以通过记录我们当前即将要插入的元素，通过额外的一个元素的空间，来换取一直进行的交换操作。\n以上伪代码的C++实现如下\n#include \u0026lt;algorithm\u0026gt; template\u0026lt;typename T\u0026gt; void insertionSort(T arr[], int n) { for (int i = 1; i \u0026lt; n; i++) { for (int j = i; j \u0026gt; 0 \u0026amp;\u0026amp; arr[j - 1] \u0026gt; arr[j]; j--) { std::swap(arr[j - 1], arr[j]); } } } 2.3 略微改进的插入排序算法 上面在2.2节中讨论到可以通过额外的一个临时变量存储当前待插入的元素，从而减少一直进行的交换操作，伪码如下：\ni ← 1 while i \u0026lt; length(A) x ← A[i] j ← i - 1 while j \u0026gt;= 0 and A[j] \u0026gt; x A[j+1] ← A[j] j ← j - 1 end while A[j+1] ← x i ← i + 1 end while 注意算法的几个细节：\n  使用临时变量保存了即将插入的元素A[i]的值，在内层循环中一直向后移动元素，直到找到A[i]归属的那个位置\n  内层代码中赋值使用的是A[j+1] = A[j]，和2.2节中略有不同，这些是实现中边界条件的一些细节，在实际编码中需要格外注意（最好是手写一个简单的数组来模拟）\n  以上伪码的C++实现如下：\ntemplate\u0026lt;typename T\u0026gt; void insertionSort(T arr[], int n) { for (int i = 1; i \u0026lt; n; i++) { T tmp = std::move(arr[i]); int j = i-1; for (; j \u0026gt;= 0 \u0026amp;\u0026amp; arr[j] \u0026gt; tmp; j--) { arr[j + 1] = std::move(arr[j]); } arr[j+1] = std::move(tmp); } } 以上代码在设置 int j = i - 1，写起来特别别扭，建议还是用 int j = i的方式，赋值使用 arr[j] = arr[j-1]的方式，更加自然一点。\n另外代码中使用了C++的移动函数，如果数组的元素是特别大的对象，那么这样处理减少了拷贝对象的过程\n2.4 递归的实现 插入排序可以采用递归的方式来实现，插入排序采用递归的方式没有任何优势可言，不过可以考察对于递归和插入排序的理解，递归的思路如下：\n 基本情形(Base): 如果数组长度为1，排序完成 递归的处理最开始的n-1个元素 插入最后一个元素到已经排好序的子数列中  实现代码如下：\ntemplate\u0026lt;typename T\u0026gt; void insertionSort(T arr[], int n) { if (n \u0026lt;= 1) return; insertionSort(arr, n - 1); T last = arr[n - 1]; int j = n - 1; while (j \u0026gt; 0 \u0026amp;\u0026amp; arr[j-1] \u0026gt; last) { arr[j] = arr[j-1]; j--; } arr[j] = last; } 也就是在已经排好序的数组中再新增一个元素\n3. 算法的复杂度分析 最好情况：\n当数组已经是排好序的情况下，内层的循环只需要进行一次，时间复杂度是O(n)\n最坏的情况：\n当数组完全是逆序的时候，整个循环需要依次比较 1+2+3+\u0026hellip;+n-1次，于是时间复杂度是 $ O(n^2) $\n平均情况：\n平均的时间复杂度也是 $ O(n^2) $\n4. 参考资料 1.Insertion sort\n2.Insertion Sort\n3.Recursive Insertion Sort\n4.Insertion Sort by swapping???\n5.Introduction To Algorithms(chapter 2.1)\n","description":"","id":6,"section":"posts","tags":null,"title":"排序算法之插入排序","uri":"https://blog.healex.xyz/posts/insertion_sort/"},{"content":"1. 简介 B树有两种分类的方式：\n（1）按度来定义（degree）\n这种定义方法在算法导论一书中提及的，\n一棵度为t的B树：\n定义为：非根内节点的最少孩子数是t，并且强制非根内节点的最大孩子数是2t\n（2）按阶来定义（order）\n这种定义方法是在The Art of Computer Programming 一书中定义的，\n一棵m阶的B树：\n定义为：非根内节点的最大孩子数量是m，非根内节点的最小孩子数量是 m/2 向上取整\n这两种方式定义下的最简单B数就有所差异了，按度定义的话最小的B树是2-3-4树，按阶的方式定义最小的B树是2-3树\n参考资料 1. B-tree\n2.stackoverflow: What is the difference btw “Order” and “Degree” in terms of Tree data structure\n","description":"","id":7,"section":"posts","tags":null,"title":"B树(B-tree)","uri":"https://blog.healex.xyz/posts/btree/"},{"content":"1. 简介  OpenWRT从19.07开始逐步将网页的渲染模式从服务端移到客户端，由此带来的一个显著的变化是luci开发的Lua代码大幅减少，取而代之的是JavaScript代码的增加。今后在处理界面的逻辑上基本上都是使用JavaScript来处理了。OpenWRT 19.07系列应该是一个逐步转型的版本，在这个版本中可以支持两种模式的luci-app开发，包括：\n 使用传统的Lua方式编写网页界面（主要是 Call、Template、CBI这三种方式） 使用新式的JS+css+html的方式来编写界面   在OpenWRT 19.07中由于有大量的app尚未迁移到新的模式，为了兼容老的luci-app，可以安装luci-app-compat这个工具包来实现运行老的luci-app\n本文主要说明当前luci-app如何去编辑网页的菜单栏，把我们编写的程序放在对应的菜单栏下（菜单栏这个说法可能不准确，这个是我个人的称呼，指的是下图的内容）\n 在本文写作时，最新的19.07版本是19.07.7，在安装这个版本后，我发现当前的luci-app主要有三种形态：\n 完全没有迁移的app，还是使用18.06方式编写的界面 部分迁移的app，使用兼容模式运行 完全使用JavaScript改写的app  以一个对应的luci-app来说明每一种模式\n2. 未迁移的luci-app  在OpenWRT19.07.7的版本中，可以去opkg安装 luci-app-https-dns-proxy 这个luci-app，它就是尚未迁移的一个app，在安装之后，主要添加的文件包括：\n /usr/lib/lua/luci/controller/https-dns-proxy.lua  这个在菜单栏上的Services目录下添加了 DNS HTTPS Proxy这一项，查看文档中的内容：\nmodule(\u0026#34;luci.controller.https-dns-proxy\u0026#34;, package.seeall) function index() if nixio.fs.access(\u0026#34;/etc/config/https-dns-proxy\u0026#34;) then entry({\u0026#34;admin\u0026#34;, \u0026#34;services\u0026#34;, \u0026#34;https-dns-proxy\u0026#34;}, cbi(\u0026#34;https-dns-proxy\u0026#34;), _(\u0026#34;DNS HTTPS Proxy\u0026#34;)).acl_depends = { \u0026#34;luci-app-https-dns-proxy\u0026#34; } entry({\u0026#34;admin\u0026#34;, \u0026#34;services\u0026#34;, \u0026#34;https-dns-proxy\u0026#34;, \u0026#34;action\u0026#34;}, call(\u0026#34;https_dns_proxy_action\u0026#34;), nil).leaf = true end end function https_dns_proxy_action(name) local packageName = \u0026#34;https-dns-proxy\u0026#34; local http = require \u0026#34;luci.http\u0026#34; local sys = require \u0026#34;luci.sys\u0026#34; local util = require \u0026#34;luci.util\u0026#34; if name == \u0026#34;start\u0026#34; then sys.init.start(packageName) elseif name == \u0026#34;action\u0026#34; then util.exec(\u0026#34;/etc/init.d/\u0026#34; .. packageName .. \u0026#34; reload \u0026gt;/dev/null 2\u0026gt;\u0026amp;1\u0026#34;) elseif name == \u0026#34;stop\u0026#34; then sys.init.stop(packageName) elseif name == \u0026#34;enable\u0026#34; then sys.init.enable(packageName) elseif name == \u0026#34;disable\u0026#34; then sys.init.disable(packageName) end http.prepare_content(\u0026#34;text/plain\u0026#34;) http.write(\u0026#34;0\u0026#34;) end 在传统的luci-app开发过程中，对于一个菜单的响应有3种方式：分别是执行指定方法（Action）、访问指定页面（Views）以及调用CBI Module。\n第一种可以直接调用指定的函数，比如点击菜单项就直接重启路由器等等，比如写为“call(\u0026#34;function_name\u0026#34;)”，然后在lua文件下编写名为function_name的函数就可以调用了。 第二种可以访问指定的页面，比如写为“template(\u0026#34;myapp/mymodule\u0026#34;)”就可以调用/usr/lib/lua/luci/view/myapp/mymodule.htm文件了。 第三种方法无非是最方便的，比如写为“cbi(\u0026#34;myapp/mymodule\u0026#34;)”就可以调用/usr/lib/lua/luci/model/cbi/myapp/mymodule.lua文件了。 可以看到响应菜单的方式是通过调用cbi和call的方式进行的，cbi的model文件位置在 /usr/lib/lua/luci/model/cbi/https-dns-proxy.lua\n以上就是传统的luci-app开发方式，主要使用lua语言进行操作的交互响应。\n3. 部分迁移的luci-app  部分迁移的luci-app主要是将菜单的响应部分迁移到 javascript中（/www/luci-static/resources)，在19.07.7下的 luci-app-adblock 就是一个部分迁移的例子\n在 luci-app-adblock 中，配置菜单栏上的菜单项也是在controller目录中的adblock.lua文件中进行的，这个文件内容如下：\n-- stub lua controller for 19.07 backward compatibility module(\u0026#34;luci.controller.adblock\u0026#34;, package.seeall) function index() entry({\u0026#34;admin\u0026#34;, \u0026#34;services\u0026#34;, \u0026#34;adblock\u0026#34;}, firstchild(), _(\u0026#34;Adblock\u0026#34;), 60) entry({\u0026#34;admin\u0026#34;, \u0026#34;services\u0026#34;, \u0026#34;adblock\u0026#34;, \u0026#34;overview\u0026#34;}, view(\u0026#34;adblock/overview\u0026#34;), _(\u0026#34;Overview\u0026#34;), 10) entry({\u0026#34;admin\u0026#34;, \u0026#34;services\u0026#34;, \u0026#34;adblock\u0026#34;, \u0026#34;dnsreport\u0026#34;}, view(\u0026#34;adblock/dnsreport\u0026#34;), _(\u0026#34;DNS Report\u0026#34;), 20) entry({\u0026#34;admin\u0026#34;, \u0026#34;services\u0026#34;, \u0026#34;adblock\u0026#34;, \u0026#34;blacklist\u0026#34;}, view(\u0026#34;adblock/blacklist\u0026#34;), _(\u0026#34;Edit Blacklist\u0026#34;), 30) entry({\u0026#34;admin\u0026#34;, \u0026#34;services\u0026#34;, \u0026#34;adblock\u0026#34;, \u0026#34;whitelist\u0026#34;}, view(\u0026#34;adblock/whitelist\u0026#34;), _(\u0026#34;Edit Whitelist\u0026#34;), 40) entry({\u0026#34;admin\u0026#34;, \u0026#34;services\u0026#34;, \u0026#34;adblock\u0026#34;, \u0026#34;logread\u0026#34;}, view(\u0026#34;adblock/logread\u0026#34;), _(\u0026#34;Log View\u0026#34;), 50) end 可以看到它的调用方式不是传统luci-app方式那3种方式中的任何一种，而是一种全新的使用JavaScript进行响应的方式，这里面的view(adblock/*)对应的是/www/luci-static/resources/view 目录下的js文件\n也就是说在这种过渡方案模式下，有以下特点：\n 菜单栏的配置还是使用传统的luci-app方式进行的，仍然是在 controller 目录中配置 对于菜单栏的响应设置在新的JavaScript脚本中进行  4. 完全迁移的luci-app 上面提到了过渡模式下菜单栏和对菜单栏响应方式的变化，最新的OpenWRT的实现中，菜单栏和对菜单栏的响应都不在传统的 /usr/lib/lua/luci 目录下进行了，而是采用下面这种处理方式\n 菜单栏的配置修改到 /usr/share/luci/menu.d 目录中，并且配置文件使用.json文件 对菜单栏的响应修改到 /www/luci-static/resources 目录中，并且响应的脚本都是.js文件  我们查看这个menu.d目录中的 luci-base.json 文件，可以看到文件中列举出所有标题栏上显示的内容\n{ \u0026#34;admin\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Administration\u0026#34;, \u0026#34;order\u0026#34;: 10, \u0026#34;action\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;firstchild\u0026#34;, \u0026#34;recurse\u0026#34;: true }, \u0026#34;auth\u0026#34;: { \u0026#34;methods\u0026#34;: [ \u0026#34;cookie:sysauth\u0026#34; ], \u0026#34;login\u0026#34;: true } }, \u0026#34;admin/status\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Status\u0026#34;, \u0026#34;order\u0026#34;: 10, \u0026#34;action\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;firstchild\u0026#34;, \u0026#34;preferred\u0026#34;: \u0026#34;overview\u0026#34;, \u0026#34;recurse\u0026#34;: true } }, \u0026#34;admin/system\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;System\u0026#34;, \u0026#34;order\u0026#34;: 20, \u0026#34;action\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;firstchild\u0026#34;, \u0026#34;preferred\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;recurse\u0026#34;: true } }, \u0026#34;admin/vpn\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;VPN\u0026#34;, \u0026#34;order\u0026#34;: 30, \u0026#34;action\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;firstchild\u0026#34;, \u0026#34;recurse\u0026#34;: true } }, \u0026#34;admin/services\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Services\u0026#34;, \u0026#34;order\u0026#34;: 40, \u0026#34;action\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;firstchild\u0026#34;, \u0026#34;recurse\u0026#34;: true } }, ... //省略其他配置 }  如果我们想要添加自己的顶层菜单，是可以直接编辑这个文件的。但是并不推荐这么做，因为如果每一个组织或个人开发的程序都要添加自己的顶层菜单，那么会造成这个文件修改的混乱，更好的办法是自己创建一个.json的文件，并采用类似luci-base.js 的写法，比如我想创建一个名称是\u0026quot;HZX\u0026quot;的顶层菜单，那么可以添加一个文件\nluci-hzxtopmenu.js文件，文件内容如下：\n{ \u0026#34;admin/hzxtopmenu\u0026#34;: { //菜单对应在网页url中的地址后缀 \u0026#34;title\u0026#34;: \u0026#34;HZX\u0026#34;, //菜单栏上显示的名称 \u0026#34;order\u0026#34;: 80, //菜单栏的显示顺序（越大越在后面） \u0026#34;action\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;firstchild\u0026#34;, \u0026#34;recurse\u0026#34;: true } } } 只添加这一个文件并不能在菜单栏上显示 \u0026ldquo;HZX\u0026rdquo; ，我们需要在 \u0026ldquo;HZX\u0026rdquo; 下面添加一个子菜单选项，添加方式也是模仿已有app的写法，比如我们创建一个luci-app-goshadowsock2.json的文件，文件内容如下：\n{ \u0026#34;admin/hzxtopmenu/goshadowsocks2\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;GoShadowsocks2\u0026#34;, \u0026#34;order\u0026#34;: 10, \u0026#34;action\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;view\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;goshadowsocks2/overview\u0026#34; } } } 这样就可以在HZX菜单项的下面添加一个叫GoShadowsocks2的子菜单项，并且点击它之后的响应转到 /www/luci-static/resources/view/goshadowsocks2/overview.js 文件中去处理，后续要做的事情就是使用JavaScript脚本完善用户点击的响应。\n下图是添加这些文件后的效果\n","description":"","id":8,"section":"posts","tags":null,"title":"OpenWRT-19.07Luci编辑菜单方法","uri":"https://blog.healex.xyz/posts/edit_menu_openwrt19.07/"},{"content":"1. 简介 OpenWRT19.07的一个重大的改动是将之前OpenWRT的Luci框架做了比较大的调整，最主要集中在将Luci的渲染方式从之前的服务端渲染模式调整到客户端的渲染模式。据OpenWRT官方说这种改动可以提升默写老旧设备的性能，将渲染网页的工作从路由器转移到用户的客户端设备。\n由于OpenWRT中luci-app非常众多，在本文写作时（最新版本是19.07.7）官方feeds中的luci-application仍然只改写了一小部分，后续估计官方会持续推进。鉴于目前19.07版本处于一种新旧方式过渡的阶段，大量老的使用lua编写的app尚未完全移植，因此如果发现老的app在19.07上运行异常（大部分都是由于cbi.lua造成的），官方给出了一些建议，包括：\n 安装luci-compat包（提供老代码的兼容方式运行） 如果页面加载缓慢，可以考虑安装 uhttpd-mod-ubus 页面加载缓慢或修改设置之后，建议重新打开浏览器标签页（或者重启浏览器）  以下我们对 19.07前后两种不同方式的luci-app开发作一个比较，挑选18.06（19.07的上一个稳定发行版）和19.07进行对比分析\n2. 18.06的luci-app风格 2.1 luci-app开发的主要方式 主要是使用openwrt提供的框架，使用lua语言进行开发，采用MVC的架构方式，在 /usr/lib/lua/luci 目录中提供有 model、controller和view几个目录，在controller目录中通过编写lua文件，生成网页上的界面菜单并且指定如何处理点击菜单之后的响应。\n响应主要通过3种方式提供：\n（1）直接调用函数的方式，比如下面的示例展示了如何调用函数响应\nmodule(\u0026#34;luci.controller.myapp.mymodule\u0026#34;, package.seeall) function index() entry({\u0026#34;click\u0026#34;, \u0026#34;here\u0026#34;, \u0026#34;now\u0026#34;}, call(\u0026#34;action_tryme\u0026#34;), \u0026#34;Click here\u0026#34;, 10).dependent=false end function action_tryme() luci.http.prepare_content(\u0026#34;text/plain\u0026#34;) luci.http.write(\u0026#34;Haha, rebooting now...\u0026#34;) luci.sys.reboot() end 再我们点击某个菜单项时，这个菜单会调用action_tryme函数\n（2）通过调用一个html页面来响应\nentry({\u0026#34;my\u0026#34;, \u0026#34;new\u0026#34;, \u0026#34;template\u0026#34;}, template(\u0026#34;myapp-mymodule/helloworld\u0026#34;), \u0026#34;Hello world\u0026#34;, 20).dependent=false 代码会调用 /usr/lib/lua/luci/view/myapp-mymodule/helloworld.htm这个页面来响应用户的点击\n（3）通过CBI的方式来响应\n这种方式也是用的比较多的一种方式，它通过编写一个lua文件来生成一个网页（包含大量的网页中控件），这些控件对应着lua中的一些类型，并且这些类型直接和uci的配置文件绑定，示例如下：\nm = Map(\u0026#34;network\u0026#34;, \u0026#34;Network\u0026#34;) -- 对应着一个配置文件 /etc/config/network s = m:section(TypedSection, \u0026#34;interface\u0026#34;, \u0026#34;Interfaces\u0026#34;) -- s对应着network这个文件中的某一个配置块 s.addremove = true -- Allow the user to create and remove the interfaces function s:filter(value) return value ~= \u0026#34;loopback\u0026#34; and value -- Don\u0026#39;t touch loopback end s:depends(\u0026#34;proto\u0026#34;, \u0026#34;static\u0026#34;) -- Only show those with \u0026#34;static\u0026#34; s:depends(\u0026#34;proto\u0026#34;, \u0026#34;dhcp\u0026#34;) -- or \u0026#34;dhcp\u0026#34; as protocol and leave PPPoE and PPTP alone ... gw = s:option(Value, \u0026#34;gateway\u0026#34;, \u0026#34;Gateway\u0026#34;) gw:depends(\u0026#34;proto\u0026#34;, \u0026#34;static\u0026#34;) gw.rmempty = true -- Remove entry if it is empty return m -- 返回配置 当用户进行操作之后，它会把用户的操作对应到uci文件中的具体选项中，在保存的时候写入到配置文件中\n2.1 lua-app安装包的目录结构 老版本的luci-app的目录结构如下图所示：\n/ ├── etc/ │ ├── config/ │ │ └── shadowsocks // UCI 配置文件 │ │── init.d/ │ │ └── shadowsocks // init 脚本 │ └── uci-defaults/ │ └── luci-shadowsocks // uci-defaults 脚本 └── usr/ ├── bin/ │ └── ss-rules // 生成代理转发规则的脚本 └── lib/ └── lua/ └── luci/ // LuCI 部分 ├── controller/ │ └── shadowsocks.lua // LuCI 菜单配置 ├── i18n/ // LuCI 语言文件目录 │ └── shadowsocks.zh-cn.lmo └── model/ └── cbi/ └── shadowsocks/ ├── general.lua // LuCI 基本设置 ├── servers.lua // LuCI 服务器列表 ├── servers-details.lua // LuCI 服务器编辑 └── access-control.lua // LuCI 访问控制 这是一个luci-app ipk包内的文件结构，这些文件会被拷贝到OpenWRT系统中对应的位置，可以看到主题的交互文件就是在/usr/lib/lua/luci的model、controller目录中。除此之外还需要搭配一些配置文件、应用程序的启动初始化脚本、翻译文件，构成整个应用程序。\n3. 19.07的luci-app风格 新的luci-app把之前的模式进行了非常多的修改，首先一个最主要的改动就是减少了大量的lua代码，新的luci-app采用的是Javascript进行开发，并且页面基本上都是使用网页的方式来呈现（也就是直接编写html的文档，有点类似于18.06响应模式的第2种）\n新的luci-app包的文件结构如下：\nopenwrt ┕feeds ┕luci ┕applications ┕luci-app-name #界面程序的主目录 ┕htdocs ┊ ┕luci-static ┊ ┕resources ┊ ┕view ┊ ┕name.js # JavaScript 脚本界面文件。 ┕po ┊ ┕zh_Hans # 此目录名称对应简体中文。 ┊ ┕name.po # 界面语言翻译文件。 ┕root ┊ ┕etc ┊ ┊ ┕uci-defaults ┊ ┊ ┕luci-app-name # 软件安装完毕后默认执行的脚本（一次性脚本），可选。 ┊ ┕usr ┊ ┕share ┊ ┕luci ┊ ┊ ┕menu.d ┊ ┊ ┕luci-app-name.json # 界面菜单，在系统菜单中的名称、顺序等。 ┊ ┕rpcd ┊ ┕acl.d ┊ ┕luci-app-name.json # 权限控制文件，管控界面能执行的各类操作。 ┕Makefile # 编译文件。 下面这个链接给出了一个移植到新版本的luci-app程序相对于老版本的修改内容：\n luci-app-minidlna的改动  https://github.com/openwrt/luci/commit/9ae591b38fedf16c3e5c97350b7182c5e28ed71f#diff-27855472049b664538cca7ef50c43df8\n4. 参考资料 1.OpenWrt 19.07.0 - First Stable Release - 6 January 2020\n2. OpenWrt达人教程之开发人员入门指南\n3. OpenWRT18.06 IPK的目录结构\n","description":"","id":9,"section":"posts","tags":null,"title":"OpenWRT 19.07 Luci框架的改变","uri":"https://blog.healex.xyz/posts/openwrt_19.07_luci_changes/"},{"content":"辗转几次还是回到这里，开始安心写作吧！\n","description":"","id":10,"section":"posts","tags":null,"title":"转圈圈","uri":"https://blog.healex.xyz/posts/my-first-post/"}]