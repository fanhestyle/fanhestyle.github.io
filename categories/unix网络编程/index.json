[{"content":"1. 概述 本章主要介绍Unix网络编程这一系列文章的相关介绍\n2. 环境 平台： Linux平台，使用Ubuntu 22.04作为测试平台，Linux内核版本 5.15.0-39-generic\n参考书籍：主要是三本书\n《Unix网络编程第三版卷一》 《Unix高级编程第三版》 《TCP-IP详解答-卷一》 另外有部分Linux相关的内容参考 《The Linux Programming Interface》\n3. 总体介绍 本系列文章主要已编码为主，重点内容以及课后的习题也列出，便于日后查阅，以后尽可能查阅使用这些文章即可，减少翻书的可能性。\n4. 本章内容 主要介绍Unix编程的基本内容，包括：\n网络编程基本的模型（客户端-服务器模型）\nOSI七层架构\n编写一个基本的时间获取客户端和服务端\n5. errno简介 errno是Unix中的错误标志码，大部分都函数出错都会返回一个errno，我们可以查询errno得知出错的原因，操作errno的主要有两个函数\nperror传入一个说明，这个说明会作为出错原因的前缀 strerror传入一个errno的错误码，得到详细的错误字符串 #include \u0026lt;stdio.h\u0026gt; void perror(const char *s); #include \u0026lt;string.h\u0026gt; char *strerror(int errnum); 另外在很早的时候errno是作为一个全局变量定义的，一般定义为 extern int errno 但是目前版本中定义为一个线程范围的变量，它的定义\nextern int *__errno_location (void) __THROW __attribute_const__; # define errno (*__errno_location ()) 可以看到errno被定义成一个函数调用的解引用形式，它调用的函数返回值是一个int*类型，因此最后的结果也是一个int类型的，当使用多线程的时候，它调用的这个函数应该是被设置为线程内的一个函数，因此返回值是Pthread-Local的变量，因此多线程之间不会共享这个变量，不会造成问题\n6. 简单的时间获取客户端 #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #define SERV_PORT 8899 #define BUF_SIZE 1024 int main(int argc, char **argv) { if (argc != 2) { fprintf(stderr, \u0026#34;Usage: %s \u0026lt;IPaddress\u0026gt;\\n\u0026#34;, argv[0]); exit(EXIT_FAILURE); } int sockfd = socket(AF_INET, SOCK_STREAM, 0); if (sockfd \u0026lt; 0) { perror(\u0026#34;socket()\u0026#34;); exit(EXIT_FAILURE); } struct sockaddr_in servaddr; bzero(\u0026amp;servaddr, sizeof(servaddr)); servaddr.sin_family = AF_INET; servaddr.sin_port = htons(SERV_PORT); int ret = inet_pton(AF_INET, argv[1], \u0026amp;servaddr.sin_addr); if (ret == 0) { fprintf(stderr, \u0026#34;Error IPaddress\\n\u0026#34;); exit(EXIT_FAILURE); } else if (ret \u0026lt; 0) { perror(\u0026#34;inet_pton()\u0026#34;); exit(EXIT_FAILURE); } socklen_t servaddr_len = sizeof(servaddr); ret = connect(sockfd, (struct sockaddr *)\u0026amp;servaddr, servaddr_len); if (ret \u0026lt; 0) { perror(\u0026#34;connect()\u0026#34;); exit(EXIT_FAILURE); } char buf[BUF_SIZE]; int n; while (1) { if ((n = read(sockfd, buf, BUF_SIZE)) \u0026lt; 0) { if (errno == EINTR) { continue; } else { perror(\u0026#34;read()\u0026#34;); exit(EXIT_FAILURE); } } else if (n == 0) { break; } write(STDOUT_FILENO, buf, n); } exit(EXIT_SUCCESS); } 7. 简单的时间获取服务端 #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #define SERV_PORT 8899 #define BUF_SIZE 1024 #define LISTENQ 1024 int main(int argc, char **argv) { int sockfd = socket(AF_INET, SOCK_STREAM, 0); if (sockfd \u0026lt; 0) { perror(\u0026#34;socket()\u0026#34;); exit(EXIT_FAILURE); } struct sockaddr_in servaddr; bzero(\u0026amp;servaddr, sizeof(servaddr)); servaddr.sin_family = AF_INET; servaddr.sin_port = htons(SERV_PORT); servaddr.sin_addr.s_addr = htonl(INADDR_ANY); int ret = bind(sockfd, (struct sockaddr *)\u0026amp;servaddr, sizeof(servaddr)); if (ret \u0026lt; 0) { perror(\u0026#34;bind()\u0026#34;); exit(EXIT_FAILURE); } listen(sockfd, LISTENQ); if (ret \u0026lt; 0) { perror(\u0026#34;listen()\u0026#34;); exit(EXIT_FAILURE); } struct sockaddr_in raddr; while (1) { socklen_t raddr_size = sizeof(raddr); int connfd = accept(sockfd, (struct sockaddr *)\u0026amp;raddr, \u0026amp;raddr_size); char raddrstr[INET_ADDRSTRLEN]; inet_ntop(AF_INET, (void *)\u0026amp;raddr.sin_addr, raddrstr, INET_ADDRSTRLEN); fprintf(stdout, \u0026#34;connection from %s:%d\\n\u0026#34;, raddrstr, htons(raddr.sin_port)); if (connfd \u0026lt; 0) { perror(\u0026#34;accept()\u0026#34;); exit(EXIT_FAILURE); } char buf[BUF_SIZE]; bzero(buf, sizeof(buf)); time_t ticks = time(NULL); snprintf(buf, sizeof(buf), \u0026#34;%.24s\\r\\n\u0026#34;, ctime(\u0026amp;ticks)); write(connfd, buf, strlen(buf)); close(connfd); } } 8. 本章习题Exercises 查看网络环境 书中使用的是 netstat 命令，当前该命令在Linux中已经过时，可以使用ip和ss命令（iproute2）替换\nnetstat -i 用于输出计算机的网络接口信息， 对应的是 ip link 命令\nnetstat -r 用于输出路由信息 对应的事 ip route 命令\n运行书中给出的客户端和服务端的例子，尝试使用不同的ip运行 可以使用multihomed的机器进行测试，可以指定任意网口的ip都可以，比如我本机运行的时候可以指定lo的ip地址（127.0.0.1），也可以指定任何一个网口的地址\n把socket的第一个参数修改为9999（AF_INET改成9999），会如何报错？ 报错如下： socket(): Address family not supported by protocol 提示协议族不对\n修改客户端的程序，统计while循环中read被调用的次数并输出 由于程序传输的内容特别少（仅仅只有一个日期）并且在本机上或者局域网环境中测试，因此测试出来的结果都是一次，事实上在TCP传输中每次读到的数据都是不一定的（TCP流式套接字的特性），但是可以保证的是客户端和服务端传输的完整内容是一样的\n","description":"","id":0,"section":"posts","tags":null,"title":"第1课 Unix网络开发概述","uri":"https://fanhestyle.github.io/posts/unixnetworkchapter1/"},{"content":" 1. 概述 本节主要讲述操作系统中线程和进程的实现原理，以及如何进行线程与进程的切换，本节是操作系统中相对比较难的内容，也是操作系统的精髓之一，必须要掌握，否则操作系统学了等于白学。\n2. 内核级线程实现原理 线程在实现中通常使用一个PCB的结构体来标识，这个PCB结构体相当于线程的一个『身份证』，一个简单的定义如下：\n1 2 3 4 5 6 7 8 /* 进程或线程的pcb,程序控制块 */ struct task_struct { uint32_t* self_kstack; // 内核线程的0级栈顶指针 enum task_status status; //线程的状态：比如阻塞还是运行还是就绪 uint8_t priority; // 线程优先级 char name[16]; //线程名称 uint32_t stack_magic; // 用这串数字做栈的边界标记,用于检测栈的溢出 }; 关于这个self_kstack需要着重的说一下，它是线程在内核态时候使用的栈顶指针，一个线程可以包含有用户态和内核态的代码，类似下图\n当线程代码在用户态运行时，使用的是用户态的栈，当线程代码在内核态运行时，使用的是内核态的栈，这个self_kstack变量就是内核态的栈顶指针\n3. 内核线程实现细节 我们在进行代码分析时，最好能知道程序的流程走向，这样跟着流程顺藤摸瓜便于理解，否则如果流程不清楚，那么就会脑子里一片混乱，我们先看一下最终调用线程的代码（注意到目前为止我们还未实现用户进程，因此这时候实现的线程实际上是内核中的几个线程之前的切换，不涉及用户进程、用户线程等内容）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 int main(void) { init_all(); thread_start(\u0026#34;k_thread_a\u0026#34;, 31, k_thread_a, \u0026#34;argA \u0026#34;); thread_start(\u0026#34;k_thread_b\u0026#34;, 8, k_thread_b, \u0026#34;argB \u0026#34;); intr_enable(); // 打开中断,使时钟中断起作用 while(1) { put_str(\u0026#34;Main \u0026#34;); }; return 0; } void k_thread_a(void* arg) { char* para = arg; while(1) { put_str(para); } } void k_thread_b(void* arg) { char* para = arg; while(1) { put_str(para); } } 可以看到我们首先创建了两个线程k_thread_a和k_thread_b以及原有的Main主线程共3个线程，程序运行的效果是：乱序的是处Main、argA、argB这三个字符串。我们的程序为什么可以输出？是什么驱动着它运行的呢？\n事实上是intr_enable这一行代码驱动它运行的，这行代码打开了中断，是的时钟中断执行 整个运转流程如下：\n于是我们的三个进程开始轮流的切换打印输出了。\n3.1 进程切换细节1 关于切换还有更深的细节需要了解，我们需要理解清楚：假设我们当前执行的是主线程Main，那么它是怎么被切换成k_thread_a线程的呢？切换的细节如下：\n上图给出了进行线程切换的总体细节，其实时钟中断不断发生，在一个线程调度中一直在进行，当时间片未耗尽时，中断处理函数仅仅是将时间片减少1就退出了，但是一旦时间片耗尽，那么在耗尽之后的中断处理程序里就要切换线程了，切换的核心是schedule函数，它会调用switch_to汇编编写的代码，借助于栈上的一些内容进行骚操作，让线程返回的时候返回到k_thread_a（同时把Main线程插入到线程就绪队列的尾部，等待再次调度）\n3.2 深入前的思考 在3.1中提到的骚操作（对栈中元素的偷龙转凤），细节还需要明晰一下，实际上这里面包含有多个内容需要理解清楚：\n（1）假设从Main切换到k_thread_a，但是k_thread_a从来就没有被调度过（第一次被调度），那么会如何处理？\n（2）假设从Main切换到k_thread_a，并且k_thread_a已经被调度过了，那么会如何处理？\n我们分两种情况分别讨论一下，在讨论之前有一些前置的知识需要了解，这个前置的知识点就是：\n如何进行C语言和汇编的互相调用，互相调用有什么需要注意的地方？ 3.3 关于C语言和汇编的互相调用 我们需要理解什么是C调用约定，什么是x86中调用的ABI约定，简单来说就是在通过栈传递参数的时候有一套约定，比如参数入栈顺序，主调函数和被调函数对于寄存器中哪些寄存器需要进行保存和恢复，关于这些内容请参考书中的描述，这里不在赘述。\n3.4 进程切换细节2 我们这里先来讨论第一种情况：\n如果Main线程切换到 k_thread_a线程，并且k_thread_a线程是第一个被调度，那么如何处理？ 这里有一个误区需要特别提出来：在《操作系统真象还原》中关于线程切换的讲解中给出了2个结构体\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 struct intr_stack { uint32_t vec_no; //低地址，表示后入栈的元素 uint32_t edi; uint32_t esi; uint32_t ebp; uint32_t esp_dummy; // 虽然pushad把esp也压入,但esp是不断变化的,所以会被popad忽略 uint32_t ebx; uint32_t edx; uint32_t ecx; uint32_t eax; uint32_t gs; uint32_t fs; uint32_t es; uint32_t ds; uint32_t err_code; void (*eip)(void); uint32_t cs; uint32_t eflags; void *esp; uint32_t ss; }; 和另外一个结构体\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 struct thread_stack { //以下寄存器是由于ABI的约定，被调方必须备份 //因为主调方可能使用了这些寄存器 //主要包括寄存器：%ebx、%esi和%edi，以及%ebp和%esp uint32_t ebp; uint32_t ebx; uint32_t edi; uint32_t esi; /* 线程第一次执行时,eip指向待调用的函数kernel_thread 其它时候,eip是指向switch_to的返回地址*/ void (*eip)(thread_func *func, void *func_arg); /***** 以下仅供第一次被调度上cpu时使用 ****/ /* 参数unused_ret只为占位置充数为返回地址 */ void (*unused_retaddr); thread_func* function; void *func_arg }; 我在阅读这一段的时候非常的不解，因为我们了解到中断发生的时候，如果发生特权级的变化，那么中断入栈的内容中会包含ss和esp，但是如果中断是在内核中发生的，未发生特权级别的变化，那么就不会入栈ss和esp，那么声明intr_stack中的\nvoid *esp; uint32_t ss; 字段一直存在，这不会造成混乱吗？\n另外还有一个问题是关于 thread_stack ，注释中有一段\n/***** 以下仅供第一次被调度上cpu时使用 ****/ /* 参数unused_ret只为占位置充数为返回地址 */ 是什么意思，为什么只有第一次运行有效的内容会在结构体中，那后续运行这些内容会不会造成程序的问题呢？\n解答：经过我多次的阅读和分析，我大概知道是什么原因了，实际上这里有点误导的嫌疑： 我们在思考的时候常常使用C语言或者C++等高级语言的方式来思考，一般我们会认为一个结构体 定义出来它是有用的，会一直存在，我们在任何时候可以改变这个结构体的内容，但是新的改变 它的数据肯定也是和这个结构体一模一样的数据方式。但是这里显然不是这样的，这里定义的 结构体实际上仅仅是一个占位而已，我们要保证我们的栈指针范围够大，可以容纳所有我们存储 的寄存器就可以，我们下次运行的时候这个结构体就不存在了，仅仅第一次占位有用，之后当 我们再调度的时候就不需要了。 再举个例子，如下图：\n以上解释了这两个定义的结构体都是第一次有用，它们尽可能的列举了当前栈中需要开辟的空间，后续的线程切换压入栈中的内容和这两个结构体中定义的成员可能不一致（比如有些成员就没有了）\n下面我们根据函数调用的流程，结合C语言的函数调用和汇编的互相调用这些知识点夹杂在一起，捋一捋整个流程，是如何将线程进行切换的（注意：这里的线程切换还仅仅是内核之间线程的切换，没有涉及到进程的切换，没有涉及到用户线程（或进程）和系统级线程（进程）之间的切换，这些内容在后文中会讲解）\n由于图太大，我分成多幅图来绘制\n继续下图绘制栈的情况，前面所绘制的都是主线程Main的内容，当我们执行switch_to的汇编代码之后，栈被进行了切换\n3.5 进程切换细节3 我们上面在3.4中讨论的是k_thread_a第一次被Main线程调度的情况，当k_thread_a已经被调度起来后，那么当它再次和Main主线程相互调度时候是什么样子的呢？\n应该如下图所示：\n至此关于内核级线程的切换便讲清楚了！\n","description":"","id":1,"section":"posts","tags":null,"title":"第12课 线程的切换","uri":"https://fanhestyle.github.io/posts/%E7%AC%AC12%E8%AF%BE-%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B%E5%88%87%E6%8D%A2/"},{"content":" 1. 概述 本文主要讲解操作系统中内存的管理方式，内存管理分为物理内存管理和虚拟内存管理，并且需要建立二者之间的关联。\n2. 管理框架 总的框架如下所示：\n3. 内存申请函数解析 在内存管理中，我们采用一种位图映射管理的方式，每一个位图的位标识一页内存块，位图类型声明如下：\n1 2 3 4 5 6 7 8 9 10 11 #define BITMAP_MASK 1 struct bitmap { uint32_t btmp_bytes_len; //位图的字节长度 uint8_t* bits; //位图的起始位置（单字节指针，类似于char*) }; void bitmap_init(struct bitmap* btmp); bool bitmap_scan_test(struct bitmap* btmp, uint32_t bit_idx); int bitmap_scan(struct bitmap* btmp, uint32_t cnt); void bitmap_set(struct bitmap* btmp, uint32_t bit_idx, int8_t value); 位图中有一个非常重要的函数，它用来返回是否存在连续的N个位（也就是我们是否可以申请连续的N块内存），实现如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 /* 判断bit_idx位是否为1,若为1则返回true，否则返回false */ bool bitmap_scan_test(struct bitmap* btmp, uint32_t bit_idx) { uint32_t byte_idx = bit_idx / 8; // 向下取整用于索引数组下标 uint32_t bit_odd = bit_idx % 8; // 取余用于索引数组内的位 return (btmp-\u0026gt;bits[byte_idx] \u0026amp; (BITMAP_MASK \u0026lt;\u0026lt; bit_odd)); } /* 在位图中申请连续cnt个位,成功则返回其起始位下标，失败返回-1 */ int bitmap_scan(struct bitmap* btmp, uint32_t cnt) { uint32_t idx_byte = 0; // 用于记录空闲位所在的字节 /* 先逐字节比较,蛮力法 */ while (( 0xff == btmp-\u0026gt;bits[idx_byte]) \u0026amp;\u0026amp; (idx_byte \u0026lt; btmp-\u0026gt;btmp_bytes_len)) { /* 1表示该位已分配,所以若为0xff,则表示该字节内已无空闲位,向下一字节继续找 */ idx_byte++; } ASSERT(idx_byte \u0026lt; btmp-\u0026gt;btmp_bytes_len); if (idx_byte == btmp-\u0026gt;btmp_bytes_len) { // 若该内存池找不到可用空间 return -1; } /* 若在位图数组范围内的某字节内找到了空闲位， * 在该字节内逐位比对,返回空闲位的索引。*/ int idx_bit = 0; /* 和btmp-\u0026gt;bits[idx_byte]这个字节逐位对比 */ while ((uint8_t)(BITMAP_MASK \u0026lt;\u0026lt; idx_bit) \u0026amp; btmp-\u0026gt;bits[idx_byte]) { idx_bit++; } int bit_idx_start = idx_byte * 8 + idx_bit; // 空闲位在位图内的下标 if (cnt == 1) { return bit_idx_start; } uint32_t bit_left = (btmp-\u0026gt;btmp_bytes_len * 8 - bit_idx_start); // 记录还有多少位可以判断 uint32_t next_bit = bit_idx_start + 1; uint32_t count = 1; // 用于记录找到的空闲位的个数 bit_idx_start = -1; // 先将其置为-1,若找不到连续的位就直接返回 while (bit_left-- \u0026gt; 0) { if (!(bitmap_scan_test(btmp, next_bit))) { // 若next_bit为0 count++; } else { count = 0; } if (count == cnt) { // 若找到连续的cnt个空位 bit_idx_start = next_bit - cnt + 1; break; } next_bit++; } return bit_idx_start; } 这个函数实现的效果如下图所示：\n4. 内存管理之虚拟内存管理 我们的虚拟内存需要被管理起来，管理虚拟内存的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /* 在pf表示的虚拟内存池中申请pg_cnt个虚拟页, * 成功则返回虚拟页的起始地址, 失败则返回NULL */ static void* vaddr_get(enum pool_flags pf, uint32_t pg_cnt) { int vaddr_start = 0, bit_idx_start = -1; uint32_t cnt = 0; if (pf == PF_KERNEL) { bit_idx_start = bitmap_scan(\u0026amp;kernel_vaddr.vaddr_bitmap, pg_cnt); if (bit_idx_start == -1) { return NULL; } while(cnt \u0026lt; pg_cnt) { bitmap_set(\u0026amp;kernel_vaddr.vaddr_bitmap, bit_idx_start + cnt++, 1); } vaddr_start = kernel_vaddr.vaddr_start + bit_idx_start * PG_SIZE; } else { // 用户内存池,将来实现用户进程再补充 } return (void*)vaddr_start; } 按照我们之前的分析，可以计算出分配的虚拟地址页的最小内存地址。\n5. 使用虚拟地址访问页目录和页表 我们在内存管理中进行操作时，不可避免的要访问到页表和页目录，由于我们在进入分页模式之后，代码中给出的地址都必须是虚拟的地址，这样就造成一种尴尬的情况：我们如何访问页目录和页表呢？实际上我们由两种方式：\n（1）我们将页表和页目录放在低1MB的内存中，由于我们分页页目录的第一项的页表和内存中的低1MB一一对应，因此我们如果把页目录和页表放在低1MB的内存中时，我们可以直接通过物理地址进行访问（因为这样设定之后低1MB的虚拟地址==物理地址）\n（2）由于我们之前的设计中没有采用（1）中的做法，而是把页目录和页表放在了1MB的上方。那么我们还可以怎么做呢？我们在页目录中的1023索引项(最高项也就是第1024项)中写入了页目录自身的物理地址，这样做带来的一个作用是：\n我们可以通过某些组合，让CPU的分页机制把页目录当成页表来处理，这样我们就可以索引到页目录和页表，达到我们可以操作它们的目的。具体做法如下：\n1 2 3 4 5 6 7 uint32_t* pte_ptr(uint32_t vaddr) { uint32_t* pte = (uint32_t*)(0xffc00000 + \\ ((vaddr \u0026amp; 0xffc00000) \u0026gt;\u0026gt; 10) + \\ PTE_IDX(vaddr) * 4); return pte; } 给我们一个地址vaddr（注意是虚拟地址），我们可以根据这个vaddr的地址，来生成一个新的虚拟地址，这个新生成的虚拟地址就是vaddr地址所在页表的虚拟地址，我们可以操作这个返回的虚拟地址，这样就相当于我们在操作页表一样\n以上代码是怎么做到的呢？\n我们需要特别注意：构造的新的new_vaddr地址的高10位是11111111，这样索引到自身，另外中间的10位也是 11111111，同样索引到自己，这两步实际上是利用页部件的转换，我们欺骗页部件，让它以为我们在找页表项的物理地址，实际上我们第一步和第二步都索引到了页目录自己，这样CPU任务我们的页目录是一个普通的页表，于是最后一步（注意啦）最后一步是拿到原始地址vaddr的中间10位，中间10位正好是在正常转换中索引页表的部分（最后一步并不是取vaddr的最低12位，以前我不知道为什么先入为主的认为是最低12位吗，这样就解释不同），最低端的12位我们是用vaddr的中间10位*4，正好模拟的是正常页部件转换中获取页表项地址的操作，于是我们得到了一个新的虚拟地址new_vaddr，通过这个地址访问到的是vaddr所在页表项的物理地址。\n另一个与之对应的函数时如何访问页目录项的物理地址（也就是页表的物理地址）\n1 2 3 4 5 6 /* 得到虚拟地址vaddr对应的pde的指针 */ uint32_t* pde_ptr(uint32_t vaddr) { /* 0xfffff是用来访问到页表本身所在的地址 */ uint32_t* pde = (uint32_t*)((0xfffff000) + PDE_IDX(vaddr) * 4); return pde; } 同样也是前两步欺骗页部件，最后的低12位是原始 vaddr的最高10位\n","description":"","id":2,"section":"posts","tags":null,"title":"第11课 内存管理","uri":"https://fanhestyle.github.io/posts/%E7%AC%AC11%E8%AF%BE-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"},{"content":" 1. 概述 本来想将特权级单独来讲解，但是考虑到特权级和中断的关系，因此将二者结合起来讲解，因为中断很大一个原因是我们想通过中断门来实现调用操作系统提供的功能，这样自然就涉及到了特权级的提升，因此二者之间有着莫大的联系\n2. 中断的分类 中断可以分为内部中断和外部中断，\n内部中断\n可屏蔽的内部中断\n不可屏蔽的内部中断\n外部中断\n可屏蔽的外部中断\n不可屏蔽的外部中断\n可以这样说，操作系统之所以可以提供如此强大的功能就是有赖于中断，操作系统是正常运转都是由中断驱动的\n3. 中断描述符 中断描述符是一种描述符，大小是8个字节，它记录了中断处理程序的入口地址，这样当硬件接收到中断号时，可以使用这个中断号去中断描述符表中获取中断描述符，然后根据这个中断描述符查找到中断处理程序，最终完成对中断的处理\n4. 中断的处理过程 整的中断过程分为CPU外和CPU内两部分。\nCPU外：外部设备的中断由中断代理芯片接收，处理后将该中断的中断向量号发送到CPU。\nCPU内：CPU执行该中断向量号对应的中断处理程序。\n中断外的处理一般是使用代理芯片进行处理（比如8259A）我们暂不关心，重点关注CPU内部的处理，因为这是我们真正需要编码的地方，整个过程如下：\n（1）处理器根据中断向量号定位中断门描述符\n中断向量号 * 8 + IDT的基地址 = 中断描述符\n（2）处理器进行特权级检查\n当前特权级CPL必须在门描述符DPL和门中目标代码段DPL之间。这是为了防止位于3特权级下的用户程序主动调用某些只为内核服务的例程\n（3）通过检查后，在中断描述符中拿到段描述符的基址和偏移地址，获取到最终运行代码的位置，并将其装载到CS和EIP中，执行相应的中断处理程序\n5. 中断处理过程中的压栈操作 中断在发生时，处理器收到一个中断向量号，根据此中断向量号在中断描述符表中找到相应的中断门描述符，门描述符中保存的是中断处理程序所在代码段的选择子及在段内偏移量，处理器从该描述符中加载目标代码段选择子到代码段寄存器CS及偏移量到指令指针寄存器EIP。注意，由于CS加载了新的目标代码段选择子，处理器不管新的选择子和任何段寄存器（包括CS）中当前的选择子是否相同，也不管这两个选择子是否指向当前相同的段，只要段寄存器被加载，段描述符缓冲寄存器就会被刷新，处理器都认为是换了一个段，属于段间转移，也就是远转移。所以，当前进程被中断打断后，为了从中断返回后能继续运行该进程，处理器自动把CS和EIP的当前值保存到中断处理程序使用的栈中。不同特权级别下处理器使用不同的栈，至于中断处理程序使用的是哪个栈，要视它当时所在的特权级别，因为中断是可以在任何特权级别下发生的。除了要保存CS、EIP外，还需要保存标志寄存器EFLAGS，如果涉及到特权级变化，还要压入SS和ESP寄存器。\n6. 中断处理结束后的出栈操作 处理器进入中断执行完中断处理程序后，还要返回到被中断的进程，这是进入中断的逆过程。中断返回是用iret指令实现的。Iret，即interrupt ret，此指令专用于从中断处理程序返回，假设在32位模式下，它从当前栈顶处依次弹出32位数据分别到寄存器EIP、CS、EFLAGS。iret指令并不清楚栈中数据的正确性，它只负责把栈顶处往上的数据，每次4字节，对号入座弹出到相关寄存器，所以在使用iret之前，一定要保证栈顶往上的数据是正确的，且从栈顶往上的顺序是EIP、CS、EFLAGS，根据特权级是否有变化，还有ESP、SS。\n","description":"","id":3,"section":"posts","tags":null,"title":"第10课 中断和特权级","uri":"https://fanhestyle.github.io/posts/%E7%AC%AC10%E8%AF%BE-%E7%89%B9%E6%9D%83%E7%BA%A7/"},{"content":" 1. 概述 本文介绍在汇编语言中的函数调用以及汇编和C的函数调用互操作的一些内容，我们假设C语言和汇编进行相互操作，那么情况有如下几种：\nC语言调用C语言所写的函数\nC语言调用汇编语言所写的函数\n汇编语言调用C语言所写的函数\n汇编语言调用汇编语言所写的函数\n对于1，C语言调用C语言都是编译器替我们处理好的，我们不用关心\n对于2，本文重点讨论\n对于3， 也是编译器帮助我们处理好，我们只需要让C的函数是导出的(extern)，那么汇编调用即可\n对于4， 编写方式可以任意，因为都是汇编语句，不需要遵循任何规则，当然我们也可以把被调用的汇编函数仿造C语言的风格来写，不过这都无所谓\n2. 调用约定 在汇编和C语言互操作的过程中，我们需要了解到调用底层ABI的一些知识。首先汇编和C语言互操作，它们的参数传递是采用栈的方式进行的。也就是说传递的参数调用方需要把参数入栈，被调用方得从栈中取出参数，这就涉及到一个问题了，栈中参数的形态是怎样的？\n另外在函数调用过程中寄存器会发生变化，我们是否要备份寄存器呢？这些都是问题\n实际上在x86的架构中有多种处理方式，这些处理方式被称为调用约定，我们主要讲一下C语言的调用约定，一般称为 cdel，约定如下：\n1. 参数使用栈传递 2. EAX，ECX，EDX由被调用者保存 3. 其余寄存器由被调用者保存 4，函数返回值存储在EAX中 5. 栈清理工作由调用者清理 6. 参数的传递方式是从右往左进行入栈 3. cdecl 函数调用过程 3.1 主调函数调用 （1）将所有调用参数压栈 （2）调用call指令 在被调函数执行中，被调函数可能会修改一些寄存器的值，导致我们主调函数当前的寄存器值会被覆盖（%ebp除外），因此如果我们在调用函数前有需要保存的寄存器值，那么我们必须在push参数之前，对这些寄存器进行压栈操作\n在被调函数开始执行前，当前进程中的栈如下图所示：\n1 2 3 4 5 6 参数N 参数N-1 ... 参数2 参数1 主调函数的返回地址 \u0026lt;----- (%esp) # 返回地址是我们主调函数call func的下一条指令 3.2 被调函数执行 这一过程分为3步：\n（1）运行代码前准备阶段\n（2）运行代码阶段\n（3）运行代码后的清理阶段\n其中（1）（3）对于所有函数调用都是一样的，只有（2）根据每个函数不同的功能而有差别（毕竟每个函数执行的作用是我们自己写的，各不相同）\n（1） 运行前准备阶段 设置阶段以下两条指令会被立刻执行\n1 2 pushl %ebp movl %esp %ebp 第一条指令用来备份当前的base pointer（也就是栈帧指针 frame pointer）%ebp，然后通过esp把当前被调函数的栈顶指针赋值给它。\nebp的作用非常关键，它起到了两个重要的作用：在其上是被调函数要使用的参数，而在其下是被调函数在函数体内声明的一些局部变量，而在ebp当口指向的就是上一个主调函数的ebp的备份值，于是ebp起到一个承上启下的作用，既可以获取函数传入的实参（高地址），又可以获取函数内部声明的局部变量（低地址），而它自己指向的地址是主调函数的ebp，并且 ebp也标识着当前被调函数的最高的地址（也就是当前栈帧的栈帧底部，esp指向当前栈帧的最高顶部） 那么ebp最原始的值是什么呢？也就是第一个启动整个进程的ebp的初始值，在参考资料2中给出的回答是：它的初值是0，在程序被装入内存的时候（elf文件的入口点被加载时，指向了一条指令 xor ebp, ebp\n准备阶段结束时的栈如下图所示：\n1 2 3 4 5 6 7 参数N \u0026lt;---------N*4+4(%ebp) 参数N-1 ... 参数2 参数1 \u0026lt;---------8(%ebp) 主调函数的返回地址 \u0026lt;---------4(%ebp) 主调函数的ebp值 %ebp \u0026lt;-------- (%ebp) = (%esp) （2）运行代码阶段 代码运行阶段就是开始实质性的执行我们所写的功能了，这个过程会涉及到几个事情：\n《1》保存寄存器的值\n一般我们会把寄存器分为几类，比如\n(a) eax, edx, ecx被称之为caller-save寄存器\n(b) ebx, esi, edi 称之为callee-save寄存器\n我们在开始执行代码的时候，第一步需要保存这些callee-save寄存器的值，在执行完函数返回之前恢复这些寄存器的值，而caller-save寄存器我们被调函数不需要保存，直接覆盖也可以（原因是caller-save寄存器在caller主调函数中有保存）\nCaller-save和callee-save是一种主调函数和被调函数之间的约定，哪些由谁来保存\n⚠️ 寄存器的保存不是一个一定要做的事情，如果主调函数没有使用任何被调函数中使用的寄存器，那么可以跳过这一步 《2》局部变量的内存分配\n函数体内使用的局部变量是分配在栈上的，如果我们要使用栈上的空间来保存局部变量，只需要移动栈顶的指针即可（增加就是分配空间，减少就是回收空间）\n1 subl $8 %esp ；在栈上分配了8个字节大小的空间 如果在函数运行一开始就可以把所有局部变量都分配好当然是最好的，这就是为什么C语言在之前的版本要求所有的变量都必须在函数体开始进行声明，这样的话我们就不用担心栈会被破坏（比如在被调函数体内再次调用其他函数，新的被调函数可以直接安排在我们分配完变量之后的空间上）\n假设我们保存了Callee-save的寄存器 %ebx，并且在函数中使用了8个字节的变量空间，那么此时栈的内容如下所示：\n1 2 3 4 5 6 7 8 9 10 参数N \u0026lt;---------N*4+4(%ebp) 参数N-1 ... 参数2 参数1 \u0026lt;---------8(%ebp) 主调函数的返回地址 \u0026lt;---------4(%ebp) 主调函数的ebp值 %ebp \u0026lt;-------- (%ebp) %ebx \u0026lt;----------4(%ebp) 局部变量1 \u0026lt;--------8(%ebp) 局部变量2 \u0026lt;--------12(%ebp) (%esp) （3）运行后清理阶段 被调函数执行完成后，它会做以下事情：\n把函数的返回结果保存在%eax之中 回收它自己使用的栈空间（给 esp加上一个值） 恢复之前保存的callee-save的值（如：popl %ebx） 恢复 %esp和%ebp的值 调用 ret 把 eip的值恢复到主调函数接下去要执行的指令（类似于 pop eip） 4，5步的代码如下图所示\n1 2 3 movl %ebp, %esp #把栈顶的指针设置成原来被调函数还未开始前的位置 popl %ebp #恢复主调函数的base pointer ret #恢复eip指针，跳转到主调函数中待执行的下一条语句继续执行 第2和3步并不是必须的，如果我们没有保存任何callee-save寄存器变量的话，按照我们上面的示例，如果没有保存%ebx，那么我们第4步当用%ebp给%esp赋值的时候，实际上已经起到了%esp增加一个值的效果了（也就是第2步不需要了）\n4. 为什么需要ebp ebp标识着一个栈帧的最低地址，通过ebp的偏移（由于ebp是固定的），我们往小地址方向可以拿到函数的参数，往大地址方向可以拿到被调函数的内部变量，使用ebp是一种惯常的做法，但是在x64程序中没有再使用ebp，因此可以说这是一种约定俗成的做法。更多关于ebp的讨论参考：[汇编中为什么需要帧指针%ebp?](汇编中为什么需要帧指针%ebp? - 知乎 (zhihu.com)\n5. 参考资料 栈和函数调用 栈和函数调用 - 凝静志远 - 博客园 Is the value of EBP before the main function important? https://reverseengineering.stackexchange.com/questions/19571/is-the-value-of-ebp-before-the-main-function-important 【主要参考资料】 Understanding how function call works https://zhu45.org/posts/2017/Jul/30/understanding-how-function-call-works/栈和函数调用 栈和函数调用 - 凝静志远 - 博客园 ","description":"","id":4,"section":"posts","tags":null,"title":"第9课 函数调用","uri":"https://fanhestyle.github.io/posts/%E7%AC%AC9%E8%AF%BE-%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8/"},{"content":" 1. 概述 本文即将开始加载最简易的内核代码，我们将控制权从Bootloader继续转交给下一棒的操作系统。\n我们的操作系统大部分使用C语言来开发，通过C语言开发生成的是可执行的ELF文件，由此带来一个问题是：我们需要解析我们生成的ELF文件，并把程序的代码和数据拷贝到内存中的指定位置，也就是说：\n（1）编译生成的操作系统是一个ELF的文件，我们需要解析它，也就是需要熟悉ELF格式\n（2）我们把ELF文件读入到内存中，我们需要指定一个保存这个映像的位置\n（3）在读入操作系统映像后，我们最终可执行的操作系统指令和数据与读取进来的映像是有差别的，我们还需要把这个映像进行“解压”，得到真正的操作系统指令和数据\n2. ELF文件 ELF（Executable and Linkable Format）是一种广泛使用在类Unix操作系统中的文件，它的文件结构分为ELF头，Programmable部分以及Sector部分，关于ELF更详细的介绍可以参考网络上专门讲ELF的内容\n3. 系统内核代码 我们最简单的系统内核代码只有一行代码\n1 2 3 4 5 6 //文件名main.c int main(void) { while(1); return 0; } 首先我们需要将其编译成可执行文件，由于我们是在编写操作系统，因此肯定是不可以使用C运行时库的，于是我们不能这样做：\ngcc main.c -o kernel.bin 因为这样去生成kernel.bin的过程中GCC会帮我们链接到C runtime库，我们正确的做法是使用AS和LD工具自行编译链接\n4. 内核的加载 在概述部分我们已经讲述了加载操作系统的过程，根据代码中的描述，加载之后的内存布局如下：\n","description":"","id":5,"section":"posts","tags":null,"title":"第8课 加载最简易的内核和ELF文件","uri":"https://fanhestyle.github.io/posts/%E7%AC%AC8%E8%AF%BE-%E5%8A%A0%E8%BD%BD%E6%9C%80%E7%AE%80%E6%98%93%E7%9A%84%E5%86%85%E6%A0%B8/"},{"content":" 1. 概述 本文主要讲解一下在x86 32位下的分页内存管理，分页机制使得我们不再直接使用和操作物理内存，而是为每一个任务（进程）分配一个独立4G空间的内存，在透过CPU提供的段页式内存管理机制，实现将我们使用的虚拟内存地址转换到实际的物理内存，这一课相对来说难度较大\n2. 分页管理的过程 2.1 内存地址转换方式 分页管理之前的内存处理 在分页管理之前我们使用的是段式内存管理，这其中也分为两种：\n实模式下的内存寻址：段地址左移4位 + 偏移地址 = 最终的物理地址\n保护模式下的寻址：段选择子\u0026ndash;\u0026gt;获取到段基址 + 偏移地址 = 最终的物理地址\n我们可以看到：所有获取到的最终都是物理地址\n开启分页之后的内存处理 在开启分页机制之后，我们在代码中给出的内存地址都是虚拟地址，虚拟地址也是采用段式的管理方式，我们通过段选择子\u0026ndash;\u0026gt;获取到段基址 + 偏移地址 = 线性地址。开启分页之后获取到的地址是线性地址，还需要将线性地址通过分页机制才能真正转换成最终的物理地址\n2.2 分页机制 我们首先拿到的是线性地址，它的结构如下：\n31 22 21 12 11 0 +---------------------+---------------------+--------------------+ | | | | | DIR | PAGE | OFFSET | | | | | +---------------------+---------------------+--------------------+ 我们把线性地址划分为3部分：高10位 + 中间10位 + 低12位，它们各有用处，总的转换过程如下图所示：\n需要注意的是：\n（1）CR3控制寄存器中存储的是页目录的物理地址（得到这个地址不需要进行页转换，否则会陷入死循环，一定要用一个地址直接可以直接拿到物理地址方式）\n（2）在页目录表中的页目录项里面存储的也是页表的物理地址（也是直接拿到物理地址，不需要进行页转换）\n2.3 页目录项和页表项 我们知道页目录项中存储的是页表的物理地址，页表项中存储的是物理页框的物理地址 ，那么页目录项和页表项的实际结构是什么样的呢？下图给出\n可以看到页目录项和页表项都是4个字节大小（4Byte = 32位），于是我们可以有下面的结论：\n页目录包含有1024个页目录项，每一个页目录项指向一个页表，一个页目录项的大小是4Byte，一个页目录项指向的页表可以申请的内存是4MB，也就是说一个页目录项对应的真实物理内存是4MB，由于有1024个页目录项，所以二级页目录项对应的物理内存大小是4GB\n每一个页表可以有1024个页表项，一个页表项是4Byte，于是一个页表占据的空间大小就是4x1024 = 4KB，同时一个页表项对应的物理内存大小是4K，于是一个页表对应的物理内存大小就是 4K * 1024 = 4M\n3. 页目录和页表的组织 页目录和页表可以在内存中的任意位置，为了简单我们将页目录和页表放在一起（一个页目录需要4K的空间，所有的页表需要4M的空间），因此我们放在的位置是紧邻 1MB内存的位置\n需要注意的是：页表项并不是所有的都一次性要申请，页目录项也是1个页目录项 可以管理4MB的内存，引入二级页表的原因就是用多少申请多少，上面所说的4K+4M是 极限的情况，也就是分配所有4GB空间的情形，一般来说基本不可能达到 内存中组织的方式如下图所示：\n整个安排是上面的图示，但是具体有一些细节需要注意：\n页目录表最多只有1个，页表可以最多可以有1024个，我们需要合理规划一下；\n我们想把低3GB的地址留给用户进程未来使用，把3G-4G这高1GB的地址留给操作系统使用（注意我们目前正在编写的就是操作系统），也就是说我们会把目前编码的地址映射到虚拟地址的3G-4G上，如何做到这一点呢？\n结合我们上面的页转换有以下的一些规则：\n线性地址的高10位会作为页目录项索引在页目录表中查找；\n线性地址的中10位会作为页表项索引在页表中查找\n线性地址的低10位作为真正的偏移在物理地址中查找\n为了映射3GB开始的内存区域，我们把3GB转换成二进制是：0xC0000000，高10位转换成十进制是 768，也就是说我们只需要在第768项中的页目录中写入页表的物理地址，那么那个页表所对应的线性地址就是3GB以上的，有了这个理论，我们这样去做：\n（1）页目录表的第0项（索引为0）写入页表物理地址\n（2）页目录表的第768项写入页表物理地址，并且我们让写入的值和第0项相同，这样它们就都映射到相同的页表了，由于我们想把这个相同的页表都映射到低1MB内存区域，这样做的好处是：我们可以继续之前未开启分页机制的代码正确运作，也可以未来都使用3GB以上的虚拟地址来访问1MB的物理内存\n小更正：上图中绘制的内存组织方式，实际上在代码中并没有采用这种方式，代码中的页表项只有255项（都是内核占用的，低0-3GB的虚拟地址我们并没有映射页目录项到页表），正确的图示如下：【和代码一致】\n代码部分\n.type setup_page, @function setup_page: //清空页目录表中所有1024项 movl $4096, %ecx movl $0, %esi clear_page_dir_table: movb $0, PAGE_DIR_TABLE_POS(,%esi) incl %esi loop clear_page_dir_table //创建PDE movl $PAGE_DIR_TABLE_POS, %eax addl $0x1000, %eax //ebx指向索引为0的页表的物理地址 movl %eax, %ebx //页目录项中的第0项和第768项指向索引为0的页表 //也就是第0项和第768项的页目录项指向了索引为0的页表 orl $PDE_PTE_FLAG, %eax movl %eax, (PAGE_DIR_TABLE_POS) movl %eax, (PAGE_DIR_TABLE_POS + 0xc00) //页目录项的最后一项(1023索引项)指向页目录表自身 subl $0x1000, %eax movl %eax, (PAGE_DIR_TABLE_POS+4092) //创建PTE //把低1MB的内存物理地址映射到虚拟地址上 //由于每一个页表项可以对应4KB的物理内存，那么1MB的物理内存 //需要的页表项数量 = 1MB / 4k = 1024 / 4 = 256项 movl $256, %ecx movl $0, %esi movl $PDE_PTE_FLAG, %edx create_pte: movl %edx, (%ebx,%esi,4) addl $4096, %edx incl %esi loop create_pte //把剩下的操作系统页目录项填充满 movl $PAGE_DIR_TABLE_POS, %eax addl $0x2000, %eax or $PDE_PTE_FLAG, %eax movl PAGE_DIR_TABLE_POS, %ebx movl $254, %ecx movl $769, %esi create_kernel_pde: movl %eax, (%ebx,%esi,4) inc %esi addl $0x1000, %eax loop create_kernel_pde ret 4. 开启分页 开启分页机制在我们设置页目录表和页表之后，还有一些工作要做，包括\n（1）把页目录表的地址加载到CR3寄存器中（注意是物理地址）\n（2）寄存器CR0的分页位打开（第31位）\n（3）必要的一些段描述符和栈指针的修改【比如映射到3G以上内存中，需要在原来的基础上加上0xC0000000】\n代码如下：\n//读取gdt sgdt gdt_ptr //把基地址读入到%ebx movl (gdt_ptr+2), %ebx orl $0xc0000000, 0x1c(%ebx) addl $0xc0000000, (gdt_ptr+2) addl $0xc0000000, %esp //把页目录表的基地址写入到CR3控制寄存器 movl $PAGE_DIR_TABLE_POS, %eax movl %eax, %cr3 movl %cr0, %eax //打开cr0的pg位（第31位） orl $0x80000000, %eax movl %eax, %cr0 lgdt gdt_ptr ","description":"","id":6,"section":"posts","tags":null,"title":"第7课 内存管理之分页机制","uri":"https://fanhestyle.github.io/posts/%E7%AC%AC7%E8%AF%BE-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%B9%8B%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6/"},{"content":" 1. 概述 在我们继续迈进内核编程之前，首先需要能获取到当前硬件的一些信息，首要的信息是物理内存的大小，一般来说可以用BIOS中断0x15实现，分别是BIOS中断0x15的3个子功能，子功能号要存放到寄存器EAX或AX中，这3个子功能分别是：\nEAX=0xE820：遍历主机上全部内存。\nAX=0xE801：分别检测低15MB和16MB～4GB的内存，最大支持4GB。\nAH=0x88：最多检测出64MB内存，实际内存超过此容量也按照64MB返回\n从1到3的功能依次减弱，但是编码难度也是递减的，有时候为了简单获取内存大小，在满足需要的前提下可以使用2或者3完成，编写代码相对容易（主要是1需要额外的类似结构体的方式来存储获取到的信息，相对繁琐）\n2. 代码实现 对于以上提到的这3个子功能的更多参数和使用方式，最好还是去查阅相关的文档，在此如果写下来也是一些技术文档的拷贝，下面给出最后获取物理内存的代码\ntotal_mem_bytes: .long 0 //获取到的结构体类似的块信息存储在ards_buf中 ards_buf: .fill 244 //保存0x15号中断E820号中断返回结构体的个数 ards_nr: .word 0 //代码开始： xorl %ebx, %ebx movl $0x534d4150, %edx movw $ards_buf, %di //调用中断0x15中e820号中断获取内存 e820_mem_get_loop: movl $0x0000e820, %eax movl $20, %ecx int $0x15 jc e820_failed_so_try_e801 addw %cx, %di incw ards_nr cmpl $0, %ebx jnz e820_mem_get_loop movw ards_nr, %cx movl $ards_buf, %ebx xorl %edx,%edx find_max_mem_area: movl (%ebx), %eax addl 8(%ebx), %eax addl $20, %ebx cmpl %eax, %edx jge next_ards movl %eax, %edx next_ards: loop find_max_mem_area jmp mem_get_ok e820_failed_so_try_e801: movw $0xe801, %ax int $0x15 jc e801_failed_so_try88 movw $0x400, %cx mulw %cx shll $16, %edx andl $0x0000FFFF, %eax orl %eax, %edx addl $0x100000, %edx movl %edx, %esi xorl %eax, %eax movw %bx, %ax movl $0x10000, %ecx mull %ecx addl %eax, %esi movl %esi, %edx jmp mem_get_ok e801_failed_so_try88: movb $0x88, %ah int $0x15 jc err_hlt andl $0x0000FFFF, %eax movw $0x400, %cx mulw %cx shll $16, %edx orl %eax, %edx addl $0x100000, %edx mem_get_ok: movl %edx, total_mem_bytes ","description":"","id":7,"section":"posts","tags":null,"title":"第6课 获取物理内存大小","uri":"https://fanhestyle.github.io/posts/%E7%AC%AC6%E8%AF%BE-%E8%8E%B7%E5%8F%96%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98%E5%A4%A7%E5%B0%8F/"},{"content":" 1. 概述 本文对保护模式代码进行简要的分析，并给出当前内存中的布局，首先给出保护模式加载的代码\n.code16 .include \u0026#34;boot.inc\u0026#34; .section .text LOADER_STACK_TOP = LOADER_BASE_ADDR jmp loader_start GDT_BASE: .long 0x0 .long 0x0 CODE_DESC: .long 0x0000FFFF .long DESC_CODE_HIGH4 DATA_STACK_DESC: .long 0x0000FFFF .long DESC_DATA_HIGH4 //显存段的段基址是0xb8000 //显存段的段界限是 0xbffff-0xb8000 = 0x7fff 粒度是4k //所以计算出的低位数字是 0x7fff/4k = 7 VIDEO_DESC: .long 0x80000007 .long DESC_VIDEO_HIGH4 GDT_SIZE = .-GDT_BASE GDT_LIMIT = GDT_SIZE - 1 .fill 60, 8, 0 //定义3个选择子 //相当于(CODE_DESC - GDT_BASE)/8 + TI_GDT + RPL0 .equ SELECTOR_CODE, (0x0001 \u0026lt;\u0026lt; 3) + TI_GDT + RPL0 .equ SELECTOR_DATA, (0x0002 \u0026lt;\u0026lt; 3) + TI_GDT + RPL0 .equ SELECTOR_VIDEO, (0x0003 \u0026lt;\u0026lt; 3) + TI_GDT + RPL0 gdt_ptr: .word GDT_LIMIT .long GDT_BASE loadermsg: .ascii \u0026#34;2 loader in real.\u0026#34; .equ MSG_SIZE, .-loadermsg loader_start: //调用BIOS打印字符串例程 INT 0x10, 功能号 0x13 movw $LOADER_BASE_ADDR, %sp movw $loadermsg, %bp movw $MSG_SIZE , %cx movw $0x1301, %ax movw $0x001f, %bx movw $0x1800, %dx int $0x10 //准备进入保护模式 //步骤： // 1. 打开A20 // 2. 加载gdt // 3. cr0寄存器第1位置为1 inb $0x92, %al orb $0x2, %al outb %al, $0x92 lgdt gdt_ptr movl %cr0, %eax or $0x1, %eax movl %eax, %cr0 ljmp $SELECTOR_CODE, $p_mode_start .code32 p_mode_start: movw $SELECTOR_DATA, %ax movw %ax, %ds movw %ax, %es movw %ax, %ss movl $LOADER_STACK_TOP, %esp movw $SELECTOR_VIDEO, %ax movw %ax, %gs movb $\u0026#39;P\u0026#39;, %gs:160 jmp . 2. 段描述符的构造 代码中一共构造了3个段描述符，分别是：\n（1）代码段描述符\n（2）数据段描述符\n（3）显存数据段描述符\n另外还有一项是0的描述符，在GDT中的第一项必须是空，这样设计的目的是：一旦我们没有初始化段描述符，会导致CPU访问第一个位置的段描述符，于是CPU可以给出异常中断，于是我们可以根据这个提示修改我们的代码，检查是否是哪个段描述符忘记初始化，避免之后导致严重的错误。\n构造段描述符的方式在之前的课程中有介绍，分别是对8个字节的每一位进行设置（关于段描述符每一位的含义简单介绍一下）\n段描述符 高32位 31--24 基址31-24位 23 G G位(段界限按4k/1B计算) 22 D/B 操作数大小（IP和SP是16位取址0还是32位取址1） 21 L 64位/32位处理器 20 AVL Avaliable保留给应用程序 19--16 段界限19-16位 15 P 存在段，可以置换到硬盘 14--13 DPL 描述符特权级(0-4) 12 S S位（标记是系统段0/非系统段1） 11--8 TYPE 段的属性描述 7--0 段基址23~16位 低32位 31---16 段基址 15~0位 15---0 段界限 15~0位 我们上面的代码构造出的段描述符的特征是：\n（1）第0索引位置：0 段描述符（按照GDT的要求设置一个空的描述符）\n（2）第1索引位置：代码段描述符（采用了平坦模型：也就是段的基址是0，段的偏移地址最大可以到4G）\n（3）第2索引位置：数据/栈段描述符（也采用了平坦模型，段的基址是0，段的偏移地址最大扩展到4G）\n（4）第3索引位置：显存文本显示描述符，它采用的不是平坦模型，它的基址的0xB8000，可以偏移的大小最大扩展到0x7fff（这就是为什么最低为是7，因为0x7fff/4k = 7)\n我们还定义了3个选择子，分别是\nSELECTOR_CODE值是8\nSELECTOR_DATA值是16\nSELECTOR_VIDEO值是24\n正好就是我们的三个描述符相对于GDTR的偏移位置（字节单位），于是我们可以直接使用这三个选择子加载到段寄存器中来操作对应的内存空间\n3. 代码执行后的内存布局 在执行上述代码之后的内存布局如下图所示：\n","description":"","id":8,"section":"posts","tags":null,"title":"第5课 保护模式代码分析","uri":"https://fanhestyle.github.io/posts/%E7%AC%AC5%E8%AF%BE-%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/"},{"content":" 1. 概述 本文开始从实模式进入到保护模式，实模式是指老式的兼容8086的模式，在实模式下各种寄存器的宽度是16位的，程序寻址内存的时候采用的是段地址偏移4位+偏移地址，而进入到保护模式之后，寄存器的宽度大部分都是32位的，并且内存的寻址方式采用 段选择子 + 偏移地址的模式\n实模式寻址方式 保护模式寻址方式 除了上述提到的变化，保护模式还引入了更多的内容，包括任务切换、特权级管理等非常多的内容\n2. 进入保护模式步骤 CPU从刚开始加电运行到加载MBR以及后续的Bootloader都是在实模式下运行的，为了切换到保护模式下，需要以下步骤：\n（1）打开A20\n（2）加载GDT\n（3）CR0寄存器的PE位置为1\n以下一一进行解释：\n2.1 打开A20 为什么要打开A20呢？我们知道在8086模式下CPU可寻址的内存只有1MB，地址总线是20条，于是为了扩展寻址的范围，我们需要突破这个限制，这就是需要打开A20的原因，打开的方式比较简单，只需要读写0x92端口即可\ninb $0x92, %al orb $0x2, %al outb %al, $0x92 2.2 加载GDT 在保护模式下所有内存的访问不再是实模式下的段地址+偏移地址直接进行访问，而是引入了段描述符，段描述符都是8个字节，段描述符是一个总称，保护模式中涉及到的所有和内存相关的概念都与它相关，分类为：\n系统段描述符\n各种门描述符（中断门、陷阱门、调用门、任务门）\nTSS\nLDT\n用户段描述符\n代码段（一致性和非一致性代码段）\n数据段\n段描述符的8个字节（一般划分为高4字节和低4字节）内容如下：\n我们需要按照我们想访问的内存设置几个段描述符（自行组装），然后把段描述符通过 lgdt 指令加载到 GDTR寄存器中\n2.3 CR0中的PE位置为1 CR0是CPU中的一个控制寄存器，它的某些位具有特殊的作用，我们启用保护模式需要打开它的最低位（最低位设置为1），CR0寄存器的结构如下：\n开启方式如下\nmovl %cr0, %eax or $0x1, %eax movl %eax, %cr0 3. 清空流水线 当我们执行完进入保护模式的各种步骤之后，实际上还需要刷新一下流水线，由于CPU的预加载机制，因此导致可能在执行到保护模式下32位指令之前，已经有一部分16位的实模式指令在缓存中，为了让程序可以正确执行之后的语句，可以使用一条远跳转语句来达到刷新流水线的效果，指令如下\nljmp $SELECTOR_CODE, $p_mode_start 至此之后CPU就进入到保护模式下愉快的执行了！\n","description":"","id":9,"section":"posts","tags":null,"title":"第4课 进入保护模式","uri":"https://fanhestyle.github.io/posts/%E7%AC%AC4%E8%AF%BE-%E8%BF%9B%E5%85%A5%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F/"},{"content":" 1. 概述 本文开始从MBR进入到第二棒Bootloader，为操作系统的加载做准备\n2. Bootloader 操作系统开发中第一棒是从BIOS进入到MBR，在MBR中只有短短的512字节，并且里面真正的代码部分只有460字节，这对于一个操作系统的加载来说是远远不够的，于是我们需要从MBR中将控制权进一步转交给下一个新的步骤：也就是传递给Bootloader，之后Bootloader可以做一些设置和执行必要的代码，最终真正的将操作系统装载到内存中\n那么Bootloader在什么地方呢？很显然Bootloader应该是存在于磁盘中的，然后通过MBR将Bootloader读取内存中\n3. 磁盘操作 在准备磁盘操作时，需要简要的认识一下磁盘，磁盘（主要是老式的机械硬盘）的结构图如下\n磁盘通过主轴的旋转带动盘片旋转，加上磁头臂的来回移动（带动磁头运动），可以实现让磁头在磁道上移动，从而实现读写数据\n磁盘读写的细节非常繁多，在此就不进行赘述了。（其实我们完全可以利用IVT中提供的中断例程来读写磁盘）\n4. 选择加载位置 通过观察之前的1MB内存的布局，我们决定把bootloader的文件读取后存放在 0x900内存开始处（此值是随意选的，只要满足有足够的空间即可），经过设置之后的内存布局如下图所示：\n整个过程可以描述如下：\n（1）BIOS读取磁盘第1个扇区内容并将512字节的MBR拷贝到内存0x7C00处\n（2）MBR代码读取磁盘第2个扇区内容，并将loader拷贝到内存0x900处\n（3）拷贝完成之后，MBR调用jmp指令跳转到0x900处继续执行loader中的代码\n","description":"","id":10,"section":"posts","tags":null,"title":"第3课 接力第二棒Bootloader","uri":"https://fanhestyle.github.io/posts/%E7%AC%AC3%E8%AF%BE-%E6%8E%A5%E5%8A%9B%E7%AC%AC%E4%BA%8C%E6%A3%92bootloader/"},{"content":" 1. 概述 本文完善之前编写的MBR，使用操作显存的方式来输出字符\n2. 实模式下的内存布局 实模式下我们使用的内存是1MB的内存空间，这是从8086继承下来的遗产，基本上我们最后使用的是80386上的特性，由于需要使用这1MB的内存，介绍以下这1MB内存的布局\n3. 操作显存 通过上面的内存布局，我们可以在显存中写入一些数据，这样显存中写入的数据最终会在屏幕上被打印出来，由于我们编写一个简易的操作系统，因此只关心显存中的文本显示区域，也就是内存地址在(0xB8000\u0026ndash;0xBFFF)这段区域\n在显存中写入数据的时候，我们一般是以2个字节为单位。低字节是字符的ASCII码，高字节是字符属性元信息。在高字节中，低4位是字符前景色，高4位是字符的背景色。颜色用RGB红绿蓝三种基色调和，第4位用来控制亮度，若置1则呈高亮，若为0则为一般正常亮度值。第7位用来控制字符是否闪烁（不是背景闪烁）\n4. 编码 有了上述基础，那么就可以不用借助BIOS中断提供的功能来打印字符，而是直接操作显存来打印，代码如下\n.code16 .section .text movw %cs, %ax movw %ax, %ds movw %ax, %es movw %ax, %fs movw $0x7c00, %sp movw $0xb800, %ax movw %ax, %gs //清屏 movw $0x600, %ax movw $0x700, %bx movw $0x0, %cx movw $0x184f, %dx int $0x10 //显存中写入数据 movb $\u0026#39;1\u0026#39;, %gs:0x0 movb $0xA4, %gs:0x1 movb $\u0026#39; \u0026#39;, %gs:0x2 movb $0xA4, %gs:0x3 movb $\u0026#39;M\u0026#39;, %gs:0x4 movb $0xA4, %gs:0x5 movb $\u0026#39;B\u0026#39;, %gs:0x6 movb $0xA4, %gs:0x7 movb $\u0026#39;R\u0026#39;, %gs:0x8 movb $0xA4, %gs:0x9 jmp . .org 510 .word 0xaa55 ","description":"","id":11,"section":"posts","tags":null,"title":"第2课 完善MBR并使用显存","uri":"https://fanhestyle.github.io/posts/%E7%AC%AC2%E8%AF%BE-%E5%AE%8C%E5%96%84mbr%E4%BD%BF%E7%94%A8%E6%98%BE%E5%AD%98/"},{"content":" 1. 概述 从本文开始我们正式开始编码的工作，首先是所有学习语言的第一个程序”Hello,World\u0026quot;\n2. MBR简介 主引导记录（Master Boot Record）存放在磁盘的于0盘0道1扇区（扇区从1开始计数，这种标记磁盘的方式称为CHS(即柱面Cylinder磁头Header扇区Sector)表示法，另外还有一种称为LBA逻辑区块地址(Logical Block Address表示法)则是从0开始计数的）\n计算机开机上电之后会进行开机自检，自检的过程实际上是运行BIOS里面程序（BIOS程序是写死在ROM之中的代码），BIOS运行的最后一步是读取磁盘中的MBR扇区内容，并将其拷贝到内存0x7C00的位置，以上过程都是固化写死的，不用我们关心\n操作系统的启动类似于一场接力赛，BIOS选手把第一棒将给我们的MBR，从MBR开始之后就是我们需要关心的内容，于是我们需要首先编写MBR，MBR中的内容是固定的，如下图所示：\n目前我们关心的只有第一项：启动代码，后续在进行磁盘管理方面功能开发的时候需要了解第二项\n3. 编写程序 完整的代码如下\n.code16 .section .text movw %cs, %ax movw %ax, %ds movw %ax, %es movw %ax, %fs movw %ax, %gs movw $0x7c00, %sp /* 清屏利用0x06号功能,上卷全部行,则可清屏 中断号：INT x10　功能号:0x06　功能描述:上卷窗口 输入: AH 功能号= 0x06 AL 上卷行数(如果为0，表示全部) BH 上卷行属性 (CL,CH) = 窗口左上角的(X,Y)位置 (DL,DH) = 窗口右下角的(X,Y)位置 无返回值: */ movw $0x600, %ax movw $0x700, %bx movw $0x0, %cx /*VGA文本模式中,一行只能容纳80个字符,共25行， 下标从0开始,所以0x18=24,0x4f=79,DX=0x184f 左上角(0,0)，右下角(80,25) */ movw $0x184f, %dx int $0x10 //以下3行获取光标位置 movb $0x3, %ah movb $0x0, %bh int $0x10 //以下6行打印字符串 movw $message, %ax movw %ax, %bp movw $MSG_LEN, %cx movw $0x1301, %ax movw $0x2, %bx int $0x10 jmp . message: .ascii \u0026#34;Hello,World!\u0026#34; MSG_LEN = . - message .org 510 .word 0xaa55 代码基本上就是清屏和打印字符串的操作，需要注意的是：\n（1）代码中使用的功能来自于BIOS自带的一些中断处理例程（类似于我们使用的一些库函数调用）\n（2）我们生成的文件必须是纯二进制的文件，并且文件的大小固定是512个字节，这样才能满足MBR的要求\n生成文件的可以使用as和ld两个工具编译和链接，使用ld需要编写ld的脚本，由于本系列使用的链接脚本内容不是关注的重点，在此一笔带过。链接是一个庞大的主题，如果深究下去也可以写一个系列，本系列关注操作系统的编写，链接使用的仅仅是最简单的脚本，如下\nSECTIONS { . = 0x7c00; .text : {*(.text)} } OUTPUT_FORMAT(binary) 脚本的作用是让连接器把文件中的符号起始地址设置在0x7c00处，这样我们在使用BIOS把我们的代码加载到0x7C00处运行时就不会出现错误\n4. 编译并运行 编译我们使用了Makefile的脚本，随着工程的逐步壮大，有必要使用Makefile来组织整个项目，代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 mbr.bin: mbr.o @ld -T mbr.lds -m elf_i386 mbr.o -o mbr.bin mbr.o: mbr.s @as --32 mbr.s -o mbr.o .PHONY:run,clean run: make clean \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make disk \u0026amp;\u0026amp; bochs disk: @bximage -mode=\u0026#34;create\u0026#34; -hd=60M -imgmode=\u0026#34;flat\u0026#34; -q hd60M.img @dd if=mbr.bin of=hd60M.img conv=notrunc clean: @$(RM) -r *.txt *.o *.bin hd60M.img 运行效果如下：\n","description":"","id":12,"section":"posts","tags":null,"title":"第1课 初识MBR程序HelloWorld","uri":"https://fanhestyle.github.io/posts/%E7%AC%AC1%E8%AF%BE-%E5%88%9D%E8%AF%86mbr%E7%A8%8B%E5%BA%8Fhelloworld/"},{"content":"1. 概述 本文主要介绍任何搭建开发环境，个人使用的开发环境如下：\nmacOS 12.3.1 Monterey Bochs 2.7 Apple clang version 13.0.0 (clang-1300.0.27.3) 2. 搭建开发环境 安装必要的开发工具集\n在MacOS中打开终端，终端中键入gcc，弹出提示框让我们安装开发组件，直接点下载安装即可\n安装Homebrew\n我个人直接使用brew来安装Bochs，因此需要首先安装Homebrew，直接去Homebrew的官网贴一行代码到终端即可安装完成\n安装bochs\n一个命令搞定\nbrew install bochs 3. Bochs环境配置 Bochs安装好之后类似于一台虚拟的电脑已经组装好，但是要启动它还需要进行一些配置（相当于给电脑设置一些硬件参数），Bochs读取这个配置文件的顺序如下：\n1. .bochsrc in the current directory 2. bochsrc in the current directory 3. bochsrc.txt in the current directory 4. (win32 only) bochsrc.bxrc in the current directory 5. (Unix only) .bochsrc in the user\u0026#39;s home directory 6. (Unix only) bochsrc in the /etc directory 首先查看brew将bochs安装的目录\nbrew list bochs 输出如下：\n/usr/local/Cellar/bochs/2.7/bin/bochs /usr/local/Cellar/bochs/2.7/bin/bximage /usr/local/Cellar/bochs/2.7/lib/bochs/ (117 files) /usr/local/Cellar/bochs/2.7/share/bochs/ (30 files) /usr/local/Cellar/bochs/2.7/share/doc/ (8 files) /usr/local/Cellar/bochs/2.7/share/man/ (4 files) 我们可以直接在运行目录下面添加一个bochsrc的文件，文件内容如下：\n第一步，首先设置 Bochs 在运行过程中能够使用的内存，本例为 32MB megs: 32 #第二步，设置对应真实机器的 BIOS 和 VGA BIOS romimage: file=/usr/local/Cellar/bochs/2.7/share/bochs/BIOS-bochs-latest vgaromimage: file=/usr/local/Cellar/bochs/2.7/share/bochs/VGABIOS-lgpl-latest #第三步，设置 Bochs 所使用的磁盘，软盘的关键字为 floppy。 #若只有一个软盘，则使用 floppya 即可，若有多个，则为 floppya，floppyb… #floppya: 1_44=a.img, status=inserted #第四步，选择启动盘符 #boot: floppy #默认从软盘启动，将其注释 boot: disk #改为从硬盘启动。我们的任何代码都将直接写在硬盘上，所以不会再有读写软盘的操作 #第五步，设置日志文件的输出 log: bochsout.txt #第六步，开启或关闭某些功能 #下面是关闭鼠标，并打开键盘 mouse: enabled=0 #keyboard_mapping: enabled=1, map=/usr/share/bochs/keymaps/x11-pc-us.map keyboard: keymap=/usr/local/Cellar/bochs/2.7/share/bochs/keymaps/sdl2-pc-us.map # 硬盘设置 ata0: enabled=1, ioaddr1=0x1f0, ioaddr2=0x3f0, irq=14 ata0-master: type=disk, path=\u0026#34;hd60M.img\u0026#34;, mode=flat, cylinders=121, heads=16, spt=63 # 如果编译bochs的时候带了-gdbstub选项才能开启，这样就可以使用gdb联合bochs调试 # 在bochs中支持2种调试方式：(1)bochs自己带的调试器 (2)gdb远程调试bochs #gdbstub: enabled=1, port=1234, text_base=0, data_base=0, bss_base=0 display_library: sdl2 相比Linux下的配置有两个地方有差异：\n（1）display_library: sdl2 在Linux下使用的是x11的显示库\n（2）keyboard: keymap的配置使用的是sdl2-pc-us.map，而不是x11的map\n4. 编写Makefile 为了测试环境编写一个简单的Makefile文件，目前暂时没有生成目标，运行只需要输入\nmake run 即可启动\nMakefile文件如下：\n1 2 3 4 5 6 7 8 9 10 .PHONY:run,clean run: make clean \u0026amp;\u0026amp; make disk \u0026amp;\u0026amp; bochs disk: @bximage -func=\u0026#34;create\u0026#34; -hd=60M -imgmode=\u0026#34;flat\u0026#34; -sectsize=512 -q hd60M.img clean: @$(RM) -r *.txt *.o *.bin hd60M.img 备注：不同版本的bochs提供的bximage工具的参数有比较大的差异，具体使用方式请man bximage 查阅\n","description":"","id":13,"section":"posts","tags":null,"title":"第0课 开发环境搭建","uri":"https://fanhestyle.github.io/posts/%E7%AC%AC0%E8%AF%BE-%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"content":"1. 简介 快速排序是一种使用非常广泛并且高效的排序算法，它和归并排序（Merge Sort）类似，一般也是采用递归的方式来实现，它们都是分治算法(Divide-and-Conquer)算法的一些典型的应用\n2. 算法思路 快速排序的算法思路如下：\n对于一个无序的数组，我们要将其按从小到大的顺序排列，过程如下：\n如果数组元素是1，那么直接返回 从数组中挑选一个元素，一般称之为Pivot，以它为界，把小的元素都放在左侧，大的元素放在Pivot值的右侧 这样数组被分成了三部分：小于pivot值 等于pivot值 大于pivot值，我们分别用集合S1，S2，S3代替，很显然合并S1-S2-S3就是最终排好序的结果 递归的对S1和S3进行快速排序操作 3. 算法实现 3.1 我个人的实现与分析 快速排序的算法思想比较简单，在看过一篇文章就理解了，但是在实作层面，发现有非常多的细节需要处理，稍不留意就会导致数组越界或者是死循环的情况，本文再回头对这个算法进行全面的手术刀式的分析，以期望对算法的每一个细节完全理解透彻。\n原始的代码：\ntemplate\u0026lt;typename T\u0026gt; void QuickSort_Impl(T arr[], int beg, int end) { if (beg \u0026gt;= end) return; T pivot = arr[beg]; int i = beg; int j = end; while (i \u0026lt;= j) i while (arr[i] \u0026lt;= pivot) { i++; } while (arr[j] \u0026gt;= pivot) { j--; } std::swap(arr[i], arr[j]); } QuickSort_Impl(arr, beg, i - 1); QuickSort_Impl(arr, i + 1, end); } template\u0026lt;typename T\u0026gt; void quickSort(T arr[], int n) { QuickSort_Impl(arr, 0, n - 1); } 先了解一下写算法时候的思路： 每次选取待排序数组的第一个元素值作为pivot，尝试将待排序数组中的元素以pivot值为界分为左右两侧，左侧的元素都小于或等于pivot，右侧的元素都大于或者等于pivot，在进行处理的时候，选取了下标i和j分别指向数组的开头与结尾的索引值。i从前往后递增（如果arr[i] \u0026lt;= pivot），j从后往前递减（如果arr[j] \u0026gt;= pivot），如果i卡在一个大于pivot的元素处，同时j卡在一个小于pivot的元素处，那么我们交换arr[i]和arr[j]的值，这样可以把i位置的元素变成小于pivot的，j位置的元素变成大于pivot的，这样i和j又可以继续朝指定方向前进，直到i超过了j或者i和j在同一个位置，说明已经遍历完了整个数组，把数组的元素分好类了。因为i位置的元素是pivot，那么pivot是排好序的位置，接着递归的对pivot左侧和pivot右侧的子数组再进行排序，直到整个排序结束，就完成了整个算法。\n问题1 数组的越界问题 while (arr[i] \u0026lt;= pivot) { i++; } while (arr[j] \u0026gt;= pivot) { j--; } 这两个循环有可能会造成数组越界，外层的 while(i\u0026lt;=j) 是在一开始进行的判断，无法约束i和j一直递增或者递减的情况。假设整个数组arr[0]是最小值，那么在第一次选pivot的时候是arr[0]，j这个变量就会越界，因为所有的元素都比pivot大（或者等），于是j就直接变成-1了，很显然是错误的。所以我们要做的第一处修改就是约束 i 和 j 变量的取值\n我们直到如果i和j相等实际上就说明已经通过i和j遍历完了整个数组了，于是判断条件是 i \u0026lt; j\n于是代码变为：\nwhile (i \u0026lt;= j) { while (i \u0026lt; j \u0026amp;\u0026amp; arr[i] \u0026lt;= pivot) { i++; } while (i \u0026lt; j \u0026amp;\u0026amp; arr[j] \u0026gt;= pivot) { j--; } std::swap(arr[i], arr[j]); } 这样还是有一个问题，当i和j相等之后，两个内层循环进不去，一个swap语句在交换两个相等的数，并且外层的while循环一直是true，这样就进入死循环了，于是while进入的条件应该不能包括i和j相等的情况，所以外层的while循环也应该修改为while(i \u0026lt; j)\nwhile (i \u0026lt; j) { while (i \u0026lt; j \u0026amp;\u0026amp; arr[i] \u0026lt;= pivot) { i++; } while (i \u0026lt; j \u0026amp;\u0026amp; arr[j] \u0026gt;= pivot) { j--; } std::swap(arr[i], arr[j]); } 问题2 数组pivot分界的问题 在调试之后我发现数组根本每一次都没有在pivot的位置进行分界，也就是说我们期望数组在每一次找到pivot位置的时候，分成左右两侧，左侧小于pivot，右侧大约pivot（也就是数组的值如果小于pivot，那么它们的索引号一定也小于pivot），由于我们判断中arr[i] \u0026lt;= pivot的缘故，导致我们会越过pivot，也就是说最后循环退出的时候，i的位置上元素根本就不是pivot值，这样就起不到分块的作用了，于是代码修改为： arr[i] \u0026lt; pivot，把相等的条件去掉，于是代码修改为：\nwhile(i \u0026lt; j \u0026amp;\u0026amp; arr[i] \u0026lt; pivot) 问题3 递归调用的范围问题 当我们把条件修改成为 arr[i] \u0026lt; pivot 之后，伴随而来又有一个问题，如果数组的第一个元素是最小的，在第一次运行QuickSort_Impl时，我们的i就不会移动，导致退出while循环的时候i的取值是0，这样就没有办法调用 QuickSort_Impl(arr, beg, i - 1); 因为会产生一个-1的索引\n另外如果数组的第一个元素是最大的，会导致j不会移动，当进行一次swap之后，最大的元素被移动到了数组最后的位置，这时候i会一直向后移动，直到i移动到j的位置（i==j）并且是移动到数组的最后一个位置，此时 while (i \u0026lt; j \u0026amp;\u0026amp; arr[j] \u0026gt;= pivot) 这个循环不会被执行，最后进行一次swap(pivot,pivot)的操作，退出循环时候 i的取值是最大的（数组的最大索引号），这样就造成一个问题，最后一个分片的起始位置就越界了 QuickSort_Impl(arr, i + 1, end); 因为产生一个数组元素个数的索引（数组最大索引应该是size-1)\n我们直到出现这两种情况的时候，数组其实只有一个元素，也就是说就是排好序的了，于是我们在递归中加上一个判断\nif (i \u0026gt; beg) QuickSort_Impl(arr, beg, i - 1); if (i \u0026lt; end) QuickSort_Impl(arr, i + 1, end); 问题4 pivot值的处理 尽管已经按照上面的方式改动了大量的代码，但还是有问题，比如下面这个测试用例： [6,8,7,5]\n这种情况就比较麻烦了，也就是说这个pivot值要十分小心的进行处理，可以想到的处理方式如下：\n选定最开始的元素作为pivot之后，执行一次swap，把最开始的元素和结尾的元素进行一次交换 j的位置从倒数第二个元素开始（因为最后一个元素是交换过去的pivot） 最终确定好pivot应有的位置之后，把i所在的位置和数组最末尾的元素交换回来 按照这种想法改进如下：\ntemplate\u0026lt;typename T\u0026gt; void QuickSort_Impl(T*\u0026amp; arr, int beg, int end) { if (beg \u0026gt;= end) return; T pivot = arr[beg]; std::swap(arr[beg], arr[end]); int i = beg; int j = end - 1; while (i \u0026lt; j) { while (i \u0026lt; j \u0026amp;\u0026amp; arr[i] \u0026lt; pivot) { i++; } while (i \u0026lt; j \u0026amp;\u0026amp; arr[j] \u0026gt;= pivot) { j--; } std::swap(arr[i], arr[j]); } std::swap(arr[i], arr[end]); if (i \u0026gt; beg) QuickSort_Impl(arr, beg, i - 1); if (i \u0026lt; end) QuickSort_Impl(arr, i + 1, end); } 经过测试发现在只有两个元素时，这种情况下会出错。比如数组是 [2,1]时，排序结果是 [2,1]，为了处理这种情况，只需要对最后 pivot和arr[i]做一个判断即可，加上条件 if (arr[i] \u0026gt; arr[end])\n最终的快速排序的完整代码如下：\n#include \u0026lt;algorithm\u0026gt; template\u0026lt;typename T\u0026gt; void QuickSort_Impl(T*\u0026amp; arr, int beg, int end) { if (beg \u0026gt;= end) return; T pivot = arr[beg]; std::swap(arr[beg], arr[end]); int i = beg; int j = end - 1; while (i \u0026lt; j) { while (i \u0026lt; j \u0026amp;\u0026amp; arr[i] \u0026lt; pivot) { i++; } while (i \u0026lt; j \u0026amp;\u0026amp; arr[j] \u0026gt;= pivot) { j--; } std::swap(arr[i], arr[j]); } if (arr[i] \u0026gt; arr[end]) std::swap(arr[i], arr[end]); if (i \u0026gt; beg) QuickSort_Impl(arr, beg, i - 1); if (i \u0026lt; end) QuickSort_Impl(arr, i + 1, end); } template\u0026lt;typename T\u0026gt; void quickSort(T arr[], int n) { QuickSort_Impl(arr, 0, n - 1); } 这个快速排序从我看完算法描述到写出完整代码调试边界情况，整整花费了一个下午的时间，这也充分说明了理解和最终实作落到代码层面是两个完全不同的事情，平常还是需要多写。数据结构不能仅仅停留在理论上理解了，一定要落在纸上，真正的写一个可以运行的实现。\n3.2 网络上另一种实现思路(参考资料2) 4. 更好的快速排序实现(wiss参考资料1) 参考资料 书籍：Data Structures and Algorithm Analysis in C++ (Fourth Edition), by Mark Allen Weiss 7.7节-快速排序\n2. 2.8.1 QuickSort Algorithm\n3.Quicksort ","description":"","id":14,"section":"posts","tags":null,"title":"排序算法之快速排序(QuickSort)","uri":"https://fanhestyle.github.io/posts/quick_sort/"},{"content":"1. 简介 堆排序使用到了堆（优先队列）的性质，假设一个堆是小顶堆，那么最大的元素在堆顶的位置，堆排序的步骤包括两个：\n创建堆结构 依次移除堆顶的元素，移除的元素存放在数组中 从上面的描述我们可以大概的直到，堆排序需要一个额外的数组来存储排好序的队列，接着再把排好序的数组复制回原来的数组\n2. 预备知识 首先了解以下堆的特性，堆和二叉排序树不同，它并没有左右子树的约束关系，而仅仅是有一个树根和左右子树的约束关系（树根的元素一定的最小的，假设针对的是小顶堆），并且使用数组实现的堆有一些特别的特性。\n在讨论特性时，我们需要了解一下堆这种数据结构的实现（假设底层采用的是数组的实现），在我遇到的代码中有基于索引1开始的实现（也就是把数组索引为0的位置空出来，另作他用），也有使用索引位置为0开始的实现，它们的区别如下：\n根节点索引为0 根节点索引为1 左孩子(数组下标) (index * 2 + 1) (index * 2) 右孩子(数组下标) (index * 2 + 2) (index*2 + 1) 父节点(数组下标) (index - 1) / 2 (index/2) 也就是说采用索引0或者1开始其实无关紧要（但是也有人争议说采用*2 /2可以通过移位快速实现，也有人反驳提到 *2 /2 的移位实现在当今的硬件上和 +1 +2几乎误差，具体见参考资料2）\n3. 实现 在堆排序实现时，需要注意2点：\n按照之前的讨论，感觉上我们应该需要额外的一个数组空间来存储排好序的结果，但是事实上我们可以复用之前的数组，因为当数组deleteRoot之后，整个堆实际上少一个元素，我们可以把删除的元素存储在空出的数组里面，但是这样做会带来一个问题，最后得到的结果时逆序的，因此为了可以正常排序，我们需要建立的堆和我们排序的情况相反的堆，也就是当要从小到大排列的时候，我们需要创建大顶堆；当需要从大到小的情况排列时，我们需要创建小顶堆。\n堆排序不要尝试去创建一个堆数据结构，也就是说当使用C++去实现的时候，不要创建一个堆的类，这样代码太复杂了，而仅仅是创建堆序就好了，代码比较轻量级一点。\n3.1 自底向上的构建堆的方法 实现的伪代码如下：\n堆排序包括两个步骤（1）创建堆（2）移除堆顶元素 直至整个堆元素处理完\nHeapSort算法 heapsort(a, count) input: 长度为count乱序的数组 heapify(a, count) //首先创建堆 //在处理过程中使用变量end记录堆结束的位置（a[0:end]标识堆区域） // a[end:count-1]是已经拍好的排好序的元素数组 end = count - 1 //用 end 记录堆中排好序和属于堆的元素 while end \u0026gt; 0 do swap(a[end],a[0]) //交换end和a[0]，把最大的元素移除 end = end - 1 //end前移1，标识最大的元素被删除出堆，进入排好序的子列 siftDown(a,0,end) //a[0]根节点位置被移除，堆性质被破坏，重新整理堆 可以从上面的伪代码看出，堆排序需要两个子函数 heapify（创建堆）和 siftDown（在堆的性质破坏之后恢复堆的性质）\n子函数 heapify procedure heapify(a, count)\nstart = iParent(count-1) //找到最后一个元素的父节点索引号\nwhile start \u0026gt;=0 do siftDown(a, start, count-1) start = start - 1 子函数 siftDown(a, start, end) procedure siftDown(a, start, end)\nroot = start while iLeftChild(root) \u0026lt;= end do child = iLeftChild(root) nextPos = root if a[nextPos] \u0026lt; a[child] then nextPos = child if child+1 \u0026lt;= end and a[nextPos] \u0026lt; a[child+1] then nextPos = child + 1 if nextPos = root then return else swap(a[root], a[nextPos]) root = nextPos; 以下是堆排序的C++实现代码(我个人手写的，可能还需要优化)\nint parent(int childIndex) { return (childIndex - 1) / 2; } int leftChild(int parentIndex) { return (2 * parentIndex + 1); } //从pos位置节点开始下沉直到处理到叶节点 //arr:数组指针 //pos:当前调整的节点索引号（是一个子树的根节点的索引号） //n：当前堆的元素总数 template\u0026lt;typename T\u0026gt; void siftDown(T arr[], int pos, int n) { int leftChildIndex = leftChild(pos); while (leftChildIndex \u0026lt; n) { //记录我们把根节点元素移动到的下一个位置 //下一个位置有可能是左孩子或者右孩子（如果存在右孩子的话） //如果下一个节点位置通过比较根节点和左右孩子节点的值发现不需要 //移动的话，说明我们根节点的值就应该保持原地不动，也就是说已经完成了 int nextTravsalIndex = pos; if (arr[nextTravsalIndex] \u0026lt; arr[leftChildIndex]) { nextTravsalIndex = leftChildIndex; } //如果节点有右节点,并且右节点的值大于（左节点和根节点值中的较大者） if (leftChildIndex + 1 \u0026lt; n) { if (arr[nextTravsalIndex] \u0026lt; arr[leftChildIndex + 1]) { nextTravsalIndex = leftChildIndex + 1; } } //我们把根节点上的元素往下沉，但是判断左右孩子都不大于这个根节点的数， //说明当前根节点的元素位置是符合堆性质的 if (nextTravsalIndex == pos) return; std::swap(arr[nextTravsalIndex], arr[pos]); pos = nextTravsalIndex; leftChildIndex = leftChild(nextTravsalIndex); } } template\u0026lt;typename T\u0026gt; void heapify(T arr[], int n) { if (n \u0026lt;= 1) return; //从最后一个节点的父节点开始，依次减少到根节点，将每一棵子树都调整为大顶堆 for (int i = parent(n-1); i \u0026gt;= 0; i--) { siftDown(arr, i, n - 1); } } template\u0026lt;typename T\u0026gt; void heapSort(T arr[], int n) { if (n \u0026lt;= 0) return; heapify(arr, n); while (n \u0026gt; 0) { std::swap(arr[0], arr[n - 1]); n--; siftDown(arr, 0, n); } } 3.1.2 补充：递归构造下沉 在下沉的时候，可以使用迭代亦可使用递归的做法，上文中给出的是迭代的代码，此处补充一下递归下沉的代码：\n/* recursive version of siftDown 具体见参考资料4 */ template\u0026lt;typename T\u0026gt; void siftDown_recursive(T arr[], int pos, int n) { //递归退出的出口 if (pos \u0026gt; n) return; int leftChildIndex = leftChild(pos); int rightChildIndex = leftChildIndex + 1; T leftValue = arr[leftChildIndex]; int maxValueIndex = pos; if (leftChildIndex \u0026lt; n \u0026amp;\u0026amp; arr[pos] \u0026lt; arr[leftChildIndex]) maxValueIndex = leftChildIndex; if (rightChildIndex \u0026lt; n \u0026amp;\u0026amp; arr[maxValueIndex] \u0026lt; arr[rightChildIndex]) maxValueIndex = rightChildIndex; if (maxValueIndex == pos) { return; } else { std::swap(arr[pos], arr[maxValueIndex]); siftDown(arr,maxValueIndex,n); } } 3.1.3 补充：延伸阅读：见参考资料1，里面有提及一种叫”heapsort with bounce“的优化方式，我暂时没看明白，不理解它的优化点在何处，后续继续研究 3.2 自顶向下构造堆的方法 在上述的3.1中介绍的方法，创建堆的方法是从最后一个节点的父节点开始，依次往上去构造堆的方法进行的，这种做法有些tricky，可能第一时间不太容易想到，比较直观的一种做法是直接从乱序的数组第一个元素开始构造堆，这种方式应该最容易想到的做法，我们来尝试一下。\n伪代码如下：\nprocedure heapify(a, count) end = 1 //end从第一个左孩子开始（根的左孩子，根的索引是0） while end \u0026lt; count siftUp(a,0,end) end = end + 1 procedure siftUp(a, start, end) child = end while child \u0026gt; start parent = iParent(child) //计算parent的索引号 if a[parent] \u0026lt; a[child] then swap(a[parent], a[child]) child = parent else return siftUp实现的堆不能像siftDown那样，在交换元素之后可以进行“堆的修复”，** siftUp这种方式实现的堆必须每次移除元素后都重建整个堆 **\nprocedure heapsort(a, count) heapify(a,count) end = count - 1 while end \u0026gt; 0 do swap(a[end],a[0]) heapify(a,end) end = end - 1 这种方式实现的C++代码如下所示：（我手写的代码，大量使用了递归）\ntemplate\u0026lt;typename T\u0026gt; void siftUp(T arr[], int index, int n) { int parentIndex = parent(index); if (parentIndex \u0026gt;= 0 \u0026amp;\u0026amp; arr[index] \u0026gt; arr[parentIndex]) { std::swap(arr[index], arr[parentIndex]); siftUp(arr,parentIndex,n); } } template\u0026lt;typename T\u0026gt; void heapify(T arr[], int n) { for (int i = 1; i \u0026lt; n; i++) { siftUp(arr, i, n); } } template\u0026lt;typename T\u0026gt; void heapSort(T arr[], int n) { if (n \u0026lt;= 1) return; heapify(arr, n); std::swap(arr[0], arr[n - 1]); heapSort(arr, n-1); } 3.3 两种思路的比较和算法复杂度分析 3.1 的思路有点类似于从最底下的非叶节点开始，逐步向根移动，并且每次都“修补”好堆的结构\n3.2 的思路是从空的堆开始，逐步构建一个完整的堆，它是从最上面的根的子节点开始的\n需要根据算法中描述的具体操作步骤才能分析清楚这两者的特点：\n3.1 具体来说是一种“ bottom up scan , and perform a sift-down” 也就是从整体来说是 “从下往上”，但是局部确是“从上往下”\n3.2 具体来说是一种“ top down scan, and perform a sift-up\u0026quot;，从整体来说是”从上往下“，但是局部确实”从下往上“\nHeapify的时间复杂度：\n3.1 这种方式时间复杂度是O(N)\n3.2 这种方式时间复杂度是O(NlogN)\n但是两者实现的HeapSort的时间复杂度都是O(NlogN)，一般来说大家普遍实现的堆排序的算法是3.1中这种方式\n在通过数组构建堆的时候，从数组的第一个位置开始依次向后，a[0]\u0026ndash;\u0026gt;a[n-1] 这种方式称之为 sift-up的方式（从外在形式上看其实是Top-Down的方式，但是这里的sift-up指的是插入的每一步操作的方式，是将节点依次往上浮），从0开始创建一个堆；\n在通过数组构建堆的时候，从数组的最后一个位置开始依次向前，a[n-1]\u0026ndash;\u0026gt;a[0] 这种方式称之为 sift-down的方式（从外在形式上看其实是Bottom-Up的方式，但是sift-bottom指的是每一次操作一个元素采用的方式，是把节点往下沉），类似于修补一个损坏的堆\n可以通过下面的事实了解到一些复杂度区别的本质：\n往上浮的代价是节点距离根节点的距离 往下沉的代价是节点距离叶子节点的距离 很明显由于堆是完全二叉树，叶节点的节点数量明显比非叶节点多不少，于是从感性上就可以认识到往上浮肯定没有往下沉好。因为往上浮叶节点的操作代价最高，而有大量的叶节点，而往下沉根节点的代价最高，但是根节点只有一个而已。\n另外这两种思路最后获得的堆结构可能是不同的，但是最终都能得到正确的排序结果。\n更多的内容见参考资料部分\n5. 参考资料 1. Wiki: Heapsort\n2. Why in a heap implemented by array the index 0 is left unused?\n3. Weiss :Data Structures and Algorithm Analysis in C++ (Fourth Edition) Chapter 7.5 Heap Sort\n4. 堆排序(Heapsort)\n5.siftUp and siftDown operation in heap for heapifying an array\n6.How can building a heap be O(n) time complexity?\n","description":"","id":15,"section":"posts","tags":null,"title":"排序算法之堆排序","uri":"https://fanhestyle.github.io/posts/heap_sort/"},{"content":"1. 简介 希尔排序是希尔(Donald Shell)于1959年提出的一种排序算法，它是插入排序的一种改进算法，在插入排序中，我们每一次比较的是待插入数和已排好序的子数组。这样在插入的时候每一次进行相邻间元素的一次交换，希尔排序则不一样，它每次排序以一个固定的间隔进行（这个间隔被称为gap），并且最后一次的gap一定是1（也就是最后一次的排序是一次普通的插入排序）\n为什么要如此设计呢？我们考虑这样一个情形，比如下述的待排序数组\n[5,3,7,4,8,9,6,2,1]\n当我们插入排序的时候，在最后两个元素2和1进行排序的时候，我们会发现需要大量的移动操作才能把2和1放到它们应有的位置（也就是数组的开头），这样就会萌生一个想法，能不能尽快的使得2和1这样的数迅速的移动到前面呢？而不用每次一个一个数的比较前移。Shell排序就是这种想法，它用非1的间隔来进行比较，假设我们用4的间隔进行比较，在第一趟中元素4和2比较，发现2在后面，会把2移到元素4的位置，这样元素2一下子就能往前走好多步。并且当我们缩小间隔gap的时候，之前比较大间隔拍好的序列不会白费（也就是之后减少间隔的排序还是会保留之前排序的成功，相当于前人做的努力没有白费，成果一直保留在那儿），直到gap是1的最后一次排序操作，最后一次的gap为1的排序一定能保证整个数组排好序（因为它就是一次简单的插入排序嘛），而可以预期最后一次的排序需要移动的元素一定不会太多。\n另外参考资料2中给出了一个解释（也是数据结构与算法分析这本书提及的），我们把数组中逆序的数对找出来，比如上面我们举例的数组中逆序的数对包括（5，3）（5，4）（5，2）（5，1）（3，2）（3，1）\u0026hellip; 这些数对期望的对数是 $$ \\frac {n(n-1)} 4 $$ ，如果我们采取的是逐个比较相邻两个数，通过相邻两个数来决定调整相邻两个数之间的位置，这样我们一次操作最多能纠正一对逆序的数对，也就是说像插入排序、冒泡排序、选择排序这种每次只通过比较相邻的元素而进行交换的排序算法，它们的时间复杂度一定是 $$ O(n^2) $$，那么怎样提高这个排序效率呢？\n关键点就是我们不能一直比较相邻的数，而应该比较相距较远的数，这样有可能在一次交换之后能够期望达到纠正超过一个逆序对的效果，可是有人又会问：如果一次相聚较远的数，那会不会导致交换的数对中增加了额外的逆序数呢？下面我们来证明通过交换间隔较远的数对不会造成逆序数的增加。\n假设有位置i和j，i \u0026lt; j，但是a[i] \u0026gt; a[j]，我们假设数组排好序之后是从小到大排列，很显然（i，j）是一个逆序对，我们想知道交换i，j会不会造成逆序对的增加，因为i和j的交换会影响到i和j之间的数（i和j之前和之后的数和i、j的相对关系不变，因此不会影响），考虑到i和j之间的任意一个数，假设是k（i \u0026lt; k \u0026lt; j)，我们讨论下列几种情况：\na[k] \u0026gt; a[i] a[k] \u0026lt; a[j] a[i] \u0026lt; a[k] \u0026lt; a[j] 也就是说a[k]的值小于最小的，位于最小和最大之间以及大于最大的，这样就完全覆盖了a[k]的取值情况，这样我们来分析它们交换之后的效果：（我们用1，2，3来标识a[i] a[k] a[j]这样的值）\n情况1：初始是 2 3 1 ，交换i和j之后变为 1 3 2，逆序对从2变为1 情况2：初始是 3 1 2 ，交换i和j之后变为 2 1 3，逆序对从2变为1 情况3：初始是 3 2 1，交换i和j之后变为 1 2 3，逆序对从3变为0 于是我们可以说当使用间隔较大的数对交换时，一定是会减少逆序数的，有可能减少一对，也有可能减少多对，这样就至少比每次减少一对的算法要好，虽然我们不知道好的上限是好到多少，但是至少不比插入、冒泡、选择这些排序效果要差。\n事实上希尔排序的时间复杂度的证明相当的复杂，需要使用数论等非常高级的数学理论来证明，我个人还没有这个能力提供这些证明，看懂也暂时不可能，记住这个思想和为什么比普通的二次排序要好对于非理论研究的开发者来说要应该是足矣。\n2. 实现 希尔排序的实现不是特别的复杂，以下的实现包括我个人初次学习写下的一些代码\n2.1 我个人的代码 template\u0026lt;typename T\u0026gt; void shellSort(T arr[], int n) { for (int gap = n / 2; gap \u0026gt;= 1; gap /= 2) { for (int i = 0; i \u0026lt; n; i++) { for (int j = i+gap; j \u0026lt; n; j += gap) { int k = j; T tmp = arr[k]; for (; k \u0026gt;= gap \u0026amp;\u0026amp; arr[k] \u0026lt; arr[k - gap]; k -= gap) { arr[k] = arr[k - gap]; } arr[k] = tmp; } } } } 我给出的程序也是可以正确得到排序结果的，但是通过和其他标准Shell写法的程序相对比，发现了我给出来的程序会做一些额外无用的操作，从代码一眼就能看出来我写的代码有多层的循环，事实上我在阅读Shell排序的说明之后，第一时间写出来的就是上面的代码，我写的代码中第3层的循环 for(int j=i+gap; j\u0026lt;n; j+=gap) 想法是把所有间隔为gap的所有元素都找出来，然后进行一次常规的插入排序，从思路上来说是没错，但是确有点冗余，比如下面的数列\n[3,7,2,8,1,9,6,5,4] 当遍历到1时，代码会找出来子序列 [3,1,4]，然后用插入排序把所有的数排好，下次遍历到1时，还是会找出来[1,4]又再排一次，这样很明显是有重复操作的。\n问题的关键在于：shell排序是会每次比较子序列，但却不是向我这样生硬的把所有子序列都找出来排一遍。而是逐个元素遍历，找到一个元素之后和之前的相隔gap的元素进行比较，在一次最外层循环之后，每个内层的循环把新的数添加到以前遍历的都是相隔gap位置的子序列中，最终完成排序。\n2.1 Shell给出的实现 希尔最早给出的实现是选取gap的值为 $$ \\lfloor \\frac {N} {2^k} \\rfloor $$ ,实现的伪码如下：\n# Start with the largest gap and work down to a gap of 1 foreach (gap in gaps) { # Do a gapped insertion sort for this gap size. # The first gap elements a[0..gap-1] are already in gapped order # keep adding one more element until the entire array is gap sorted for (i = gap; i \u0026lt; n; i += 1) { # add a[i] to the elements that have been gap sorted # save a[i] in temp and make a hole at position i temp = a[i] # shift earlier gap-sorted elements up until the correct location for a[i] is found for (j = i; j \u0026gt;= gap and a[j - gap] \u0026gt; temp; j -= gap) { a[j] = a[j - gap] } # put temp (the original a[i]) in its correct location a[j] = temp } } C++代码实现如下：\ntemplate\u0026lt;typename T\u0026gt; void shellSort(T arr[], int n) { for (int gap = n / 2; gap \u0026gt;= 1; gap /= 2) { for (int i = gap; i \u0026lt; n; i++) { T tmp = arr[i]; int j = i; for (; j \u0026gt;= gap \u0026amp;\u0026amp; tmp \u0026lt; arr[j - gap]; j -= gap) { arr[j] = arr[j - gap]; } arr[j] = tmp; } } } 3. 时间复杂度分析 Shell排序的时间复杂度非常的繁琐，需要大量的高等数学的知识，我暂时还没能力读懂这些证明（毕竟不是数学相关专业，也对这些内容不感兴趣），因此贴一张别人论证的结论在此\n图中也给出了一些相对表现较好的gap的取值（如果gap是递增方式的，那么我们在编码时只需要找到一个比数组长度小的最大的数，逆序直到1，作为我们的gap序列即可）\n4. 参考资料 1. WiKi:Shellsort\n2.希尔排序为什么会那么牛那么快，能够证明吗？\n3.Mark Allen Weiss:Data Structures and Algorithm Analysis in C++ (Fourth Edition) 7.4 ShellSort\n","description":"","id":16,"section":"posts","tags":null,"title":"排序算法之希尔排序(ShellSort)","uri":"https://fanhestyle.github.io/posts/shell_sort/"},{"content":"1. 概述 插入排序是一种相对简单的排序算法，插入排序算法在处理过程中每次处理一个待插入的元素，将它和已经排好序的子序列进行合并成新的已排好序的部分，逐渐增长直到整个数组排序完成。\n插入排序的主要优点包括：\n实现相对简单（相比较快速排序，堆排序，归并排序来说它的代码相对较少） 对元素不太多的序列有比较好的性能 相比较其他 $ O(n^2) $ 的算法来说更加高效 算法是排序稳定的（值相等的元素位置顺序保持不变） In-place算法，只需要固定的内存空间占用（基本上只需要原先数组的空间即可） Online算法，可以来一个元素处理一个 2. 实现方式 插入排序的算法虽然简单，但是还是有一些细节需要注意，以下列举一些实现\n2.1 我最初的实现 以下是我自己在阅读插入排序描述之后给出的代码：(C++代码)\n版本1 template\u0026lt;typename T\u0026gt; void insertionSort(T array[], int n) { for (int i = 1; i \u0026lt; n; i++) { int insertPos = 0; T tmp = array[i]; for (int j = 0; j \u0026lt; i; j++) { if (array[j] \u0026lt; tmp) { insertPos++; } } for (int k = i; k \u0026gt; insertPos; --k) { array[k] = array[k - 1]; } array[insertPos] = tmp; } } 版本2 template\u0026lt;typename T\u0026gt; void insertionSort(T array[], int n) { for (int i = 1; i \u0026lt; n; i++) { int insertPos = 0; T tmp = array[i]; for (int j = 0; j \u0026lt;= i; j++) { if (array[j] \u0026lt; tmp) { insertPos++; } } for (int k = i; k \u0026gt; insertPos; --k) { array[k] = array[k - 1]; } array[insertPos] = tmp; } } 以上给出的两个版本的代码，我自己通过测试程序进行测试，测试程序如下：\nint main() { int arr[] = { 1,9,2,6,4,3,8,7,5 }; insertionSort(arr, sizeof(arr) / sizeof(arr[0])); for (auto i : arr) { std::cout \u0026lt;\u0026lt; i \u0026lt;\u0026lt; std::endl; } } 分析我个人写的代码，发现有一些需要改进的点：\n算法2实际上是有问题的\n使用测试程序是看不出来的，最后给出的结果都是1-9的顺序输出，但是算法2会造成算法的不稳定（也就是会把相等的元素的先后顺序改变）\n算法1是正确的，但是先找位置，再移动元素可以改进一下，可以从排好序的子序列的最后位置开始往前找，而不是像我写的代码这样从前往后找。因为从后往前有一个好处是交换操作可以边找边做，而从前往后找，再找到位置之后也需要移动元素，何不一边找一边移动呢？其实这也是标准的插入排序的算法实现\n2.2 常见的插入排序算法实现 以下是一种插入排序的算法伪码实现\ni ← 1 while i \u0026lt; length(A) j ← i while j \u0026gt; 0 and A[j-1] \u0026gt; A[j] swap A[j] and A[j-1] j ← j - 1 end while i ← i + 1 end while 这个算法有几个细节需要注意：\nwhile j \u0026gt; 0 and A[j-1] \u0026gt; A[j] 的And 操作必须是一个短路的and操作（类似于C/C++中的 \u0026amp;\u0026amp;，当第一个条件失效时，不会计算第二个条件）\n这个算法插入的时候，从插入点开始每次都进行了元素的交换\n进行元素的交换有一个好处是完全不需要额外的空间排序，也就是说算法整个运行过程中仅仅需要算法原始元素的存储空间。不过过多的交换或许并不是很合适，可以通过记录我们当前即将要插入的元素，通过额外的一个元素的空间，来换取一直进行的交换操作。\n以上伪代码的C++实现如下\n#include \u0026lt;algorithm\u0026gt; template\u0026lt;typename T\u0026gt; void insertionSort(T arr[], int n) { for (int i = 1; i \u0026lt; n; i++) { for (int j = i; j \u0026gt; 0 \u0026amp;\u0026amp; arr[j - 1] \u0026gt; arr[j]; j--) { std::swap(arr[j - 1], arr[j]); } } } 2.3 略微改进的插入排序算法 上面在2.2节中讨论到可以通过额外的一个临时变量存储当前待插入的元素，从而减少一直进行的交换操作，伪码如下：\ni ← 1 while i \u0026lt; length(A) x ← A[i] j ← i - 1 while j \u0026gt;= 0 and A[j] \u0026gt; x A[j+1] ← A[j] j ← j - 1 end while A[j+1] ← x i ← i + 1 end while 注意算法的几个细节：\n使用临时变量保存了即将插入的元素A[i]的值，在内层循环中一直向后移动元素，直到找到A[i]归属的那个位置\n内层代码中赋值使用的是A[j+1] = A[j]，和2.2节中略有不同，这些是实现中边界条件的一些细节，在实际编码中需要格外注意（最好是手写一个简单的数组来模拟）\n以上伪码的C++实现如下：\ntemplate\u0026lt;typename T\u0026gt; void insertionSort(T arr[], int n) { for (int i = 1; i \u0026lt; n; i++) { T tmp = std::move(arr[i]); int j = i-1; for (; j \u0026gt;= 0 \u0026amp;\u0026amp; arr[j] \u0026gt; tmp; j--) { arr[j + 1] = std::move(arr[j]); } arr[j+1] = std::move(tmp); } } 以上代码在设置 int j = i - 1，写起来特别别扭，建议还是用 int j = i的方式，赋值使用 arr[j] = arr[j-1]的方式，更加自然一点。\n另外代码中使用了C++的移动函数，如果数组的元素是特别大的对象，那么这样处理减少了拷贝对象的过程\n2.4 递归的实现 插入排序可以采用递归的方式来实现，插入排序采用递归的方式没有任何优势可言，不过可以考察对于递归和插入排序的理解，递归的思路如下：\n基本情形(Base): 如果数组长度为1，排序完成 递归的处理最开始的n-1个元素 插入最后一个元素到已经排好序的子数列中 实现代码如下：\ntemplate\u0026lt;typename T\u0026gt; void insertionSort(T arr[], int n) { if (n \u0026lt;= 1) return; insertionSort(arr, n - 1); T last = arr[n - 1]; int j = n - 1; while (j \u0026gt; 0 \u0026amp;\u0026amp; arr[j-1] \u0026gt; last) { arr[j] = arr[j-1]; j--; } arr[j] = last; } 也就是在已经排好序的数组中再新增一个元素\n3. 算法的复杂度分析 最好情况：\n当数组已经是排好序的情况下，内层的循环只需要进行一次，时间复杂度是O(n)\n最坏的情况：\n当数组完全是逆序的时候，整个循环需要依次比较 1+2+3+\u0026hellip;+n-1次，于是时间复杂度是 $ O(n^2) $\n平均情况：\n平均的时间复杂度也是 $ O(n^2) $\n4. 参考资料 1.Insertion sort\n2.Insertion Sort\n3.Recursive Insertion Sort\n4.Insertion Sort by swapping???\n5.Introduction To Algorithms(chapter 2.1)\n","description":"","id":17,"section":"posts","tags":null,"title":"排序算法之插入排序","uri":"https://fanhestyle.github.io/posts/insertion_sort/"},{"content":"1. 简介 B树有两种分类的方式：\n（1）按度来定义（degree）\n这种定义方法在算法导论一书中提及的，\n一棵度为t的B树：\n定义为：非根内节点的最少孩子数是t，并且强制非根内节点的最大孩子数是2t\n（2）按阶来定义（order）\n这种定义方法是在The Art of Computer Programming 一书中定义的，\n一棵m阶的B树：\n定义为：非根内节点的最大孩子数量是m，非根内节点的最小孩子数量是 m/2 向上取整\n这两种方式定义下的最简单B数就有所差异了，按度定义的话最小的B树是2-3-4树，按阶的方式定义最小的B树是2-3树\n参考资料 1. B-tree\n2.stackoverflow: What is the difference btw “Order” and “Degree” in terms of Tree data structure\n","description":"","id":18,"section":"posts","tags":null,"title":"B树(B-tree)","uri":"https://fanhestyle.github.io/posts/btree/"},{"content":"1. 简介 OpenWRT从19.07开始逐步将网页的渲染模式从服务端移到客户端，由此带来的一个显著的变化是luci开发的Lua代码大幅减少，取而代之的是JavaScript代码的增加。今后在处理界面的逻辑上基本上都是使用JavaScript来处理了。OpenWRT 19.07系列应该是一个逐步转型的版本，在这个版本中可以支持两种模式的luci-app开发，包括：\n使用传统的Lua方式编写网页界面（主要是 Call、Template、CBI这三种方式） 使用新式的JS+css+html的方式来编写界面 在OpenWRT 19.07中由于有大量的app尚未迁移到新的模式，为了兼容老的luci-app，可以安装luci-app-compat这个工具包来实现运行老的luci-app\n本文主要说明当前luci-app如何去编辑网页的菜单栏，把我们编写的程序放在对应的菜单栏下（菜单栏这个说法可能不准确，这个是我个人的称呼，指的是下图的内容）\n在本文写作时，最新的19.07版本是19.07.7，在安装这个版本后，我发现当前的luci-app主要有三种形态：\n完全没有迁移的app，还是使用18.06方式编写的界面 部分迁移的app，使用兼容模式运行 完全使用JavaScript改写的app 以一个对应的luci-app来说明每一种模式\n2. 未迁移的luci-app 在OpenWRT19.07.7的版本中，可以去opkg安装 luci-app-https-dns-proxy 这个luci-app，它就是尚未迁移的一个app，在安装之后，主要添加的文件包括：\n/usr/lib/lua/luci/controller/https-dns-proxy.lua 这个在菜单栏上的Services目录下添加了 DNS HTTPS Proxy这一项，查看文档中的内容：\nmodule(\u0026#34;luci.controller.https-dns-proxy\u0026#34;, package.seeall) function index() if nixio.fs.access(\u0026#34;/etc/config/https-dns-proxy\u0026#34;) then entry({\u0026#34;admin\u0026#34;, \u0026#34;services\u0026#34;, \u0026#34;https-dns-proxy\u0026#34;}, cbi(\u0026#34;https-dns-proxy\u0026#34;), _(\u0026#34;DNS HTTPS Proxy\u0026#34;)).acl_depends = { \u0026#34;luci-app-https-dns-proxy\u0026#34; } entry({\u0026#34;admin\u0026#34;, \u0026#34;services\u0026#34;, \u0026#34;https-dns-proxy\u0026#34;, \u0026#34;action\u0026#34;}, call(\u0026#34;https_dns_proxy_action\u0026#34;), nil).leaf = true end end function https_dns_proxy_action(name) local packageName = \u0026#34;https-dns-proxy\u0026#34; local http = require \u0026#34;luci.http\u0026#34; local sys = require \u0026#34;luci.sys\u0026#34; local util = require \u0026#34;luci.util\u0026#34; if name == \u0026#34;start\u0026#34; then sys.init.start(packageName) elseif name == \u0026#34;action\u0026#34; then util.exec(\u0026#34;/etc/init.d/\u0026#34; .. packageName .. \u0026#34; reload \u0026gt;/dev/null 2\u0026gt;\u0026amp;1\u0026#34;) elseif name == \u0026#34;stop\u0026#34; then sys.init.stop(packageName) elseif name == \u0026#34;enable\u0026#34; then sys.init.enable(packageName) elseif name == \u0026#34;disable\u0026#34; then sys.init.disable(packageName) end http.prepare_content(\u0026#34;text/plain\u0026#34;) http.write(\u0026#34;0\u0026#34;) end 在传统的luci-app开发过程中，对于一个菜单的响应有3种方式：分别是执行指定方法（Action）、访问指定页面（Views）以及调用CBI Module。\n第一种可以直接调用指定的函数，比如点击菜单项就直接重启路由器等等，比如写为“call(\u0026#34;function_name\u0026#34;)”，然后在lua文件下编写名为function_name的函数就可以调用了。 第二种可以访问指定的页面，比如写为“template(\u0026#34;myapp/mymodule\u0026#34;)”就可以调用/usr/lib/lua/luci/view/myapp/mymodule.htm文件了。 第三种方法无非是最方便的，比如写为“cbi(\u0026#34;myapp/mymodule\u0026#34;)”就可以调用/usr/lib/lua/luci/model/cbi/myapp/mymodule.lua文件了。 可以看到响应菜单的方式是通过调用cbi和call的方式进行的，cbi的model文件位置在 /usr/lib/lua/luci/model/cbi/https-dns-proxy.lua\n以上就是传统的luci-app开发方式，主要使用lua语言进行操作的交互响应。\n3. 部分迁移的luci-app 部分迁移的luci-app主要是将菜单的响应部分迁移到 javascript中（/www/luci-static/resources)，在19.07.7下的 luci-app-adblock 就是一个部分迁移的例子\n在 luci-app-adblock 中，配置菜单栏上的菜单项也是在controller目录中的adblock.lua文件中进行的，这个文件内容如下：\n-- stub lua controller for 19.07 backward compatibility module(\u0026#34;luci.controller.adblock\u0026#34;, package.seeall) function index() entry({\u0026#34;admin\u0026#34;, \u0026#34;services\u0026#34;, \u0026#34;adblock\u0026#34;}, firstchild(), _(\u0026#34;Adblock\u0026#34;), 60) entry({\u0026#34;admin\u0026#34;, \u0026#34;services\u0026#34;, \u0026#34;adblock\u0026#34;, \u0026#34;overview\u0026#34;}, view(\u0026#34;adblock/overview\u0026#34;), _(\u0026#34;Overview\u0026#34;), 10) entry({\u0026#34;admin\u0026#34;, \u0026#34;services\u0026#34;, \u0026#34;adblock\u0026#34;, \u0026#34;dnsreport\u0026#34;}, view(\u0026#34;adblock/dnsreport\u0026#34;), _(\u0026#34;DNS Report\u0026#34;), 20) entry({\u0026#34;admin\u0026#34;, \u0026#34;services\u0026#34;, \u0026#34;adblock\u0026#34;, \u0026#34;blacklist\u0026#34;}, view(\u0026#34;adblock/blacklist\u0026#34;), _(\u0026#34;Edit Blacklist\u0026#34;), 30) entry({\u0026#34;admin\u0026#34;, \u0026#34;services\u0026#34;, \u0026#34;adblock\u0026#34;, \u0026#34;whitelist\u0026#34;}, view(\u0026#34;adblock/whitelist\u0026#34;), _(\u0026#34;Edit Whitelist\u0026#34;), 40) entry({\u0026#34;admin\u0026#34;, \u0026#34;services\u0026#34;, \u0026#34;adblock\u0026#34;, \u0026#34;logread\u0026#34;}, view(\u0026#34;adblock/logread\u0026#34;), _(\u0026#34;Log View\u0026#34;), 50) end 可以看到它的调用方式不是传统luci-app方式那3种方式中的任何一种，而是一种全新的使用JavaScript进行响应的方式，这里面的view(adblock/*)对应的是/www/luci-static/resources/view 目录下的js文件\n也就是说在这种过渡方案模式下，有以下特点：\n菜单栏的配置还是使用传统的luci-app方式进行的，仍然是在 controller 目录中配置 对于菜单栏的响应设置在新的JavaScript脚本中进行 4. 完全迁移的luci-app 上面提到了过渡模式下菜单栏和对菜单栏响应方式的变化，最新的OpenWRT的实现中，菜单栏和对菜单栏的响应都不在传统的 /usr/lib/lua/luci 目录下进行了，而是采用下面这种处理方式\n菜单栏的配置修改到 /usr/share/luci/menu.d 目录中，并且配置文件使用.json文件 对菜单栏的响应修改到 /www/luci-static/resources 目录中，并且响应的脚本都是.js文件 我们查看这个menu.d目录中的 luci-base.json 文件，可以看到文件中列举出所有标题栏上显示的内容\n{ \u0026#34;admin\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Administration\u0026#34;, \u0026#34;order\u0026#34;: 10, \u0026#34;action\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;firstchild\u0026#34;, \u0026#34;recurse\u0026#34;: true }, \u0026#34;auth\u0026#34;: { \u0026#34;methods\u0026#34;: [ \u0026#34;cookie:sysauth\u0026#34; ], \u0026#34;login\u0026#34;: true } }, \u0026#34;admin/status\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Status\u0026#34;, \u0026#34;order\u0026#34;: 10, \u0026#34;action\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;firstchild\u0026#34;, \u0026#34;preferred\u0026#34;: \u0026#34;overview\u0026#34;, \u0026#34;recurse\u0026#34;: true } }, \u0026#34;admin/system\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;System\u0026#34;, \u0026#34;order\u0026#34;: 20, \u0026#34;action\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;firstchild\u0026#34;, \u0026#34;preferred\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;recurse\u0026#34;: true } }, \u0026#34;admin/vpn\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;VPN\u0026#34;, \u0026#34;order\u0026#34;: 30, \u0026#34;action\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;firstchild\u0026#34;, \u0026#34;recurse\u0026#34;: true } }, \u0026#34;admin/services\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Services\u0026#34;, \u0026#34;order\u0026#34;: 40, \u0026#34;action\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;firstchild\u0026#34;, \u0026#34;recurse\u0026#34;: true } }, ... //省略其他配置 } 如果我们想要添加自己的顶层菜单，是可以直接编辑这个文件的。但是并不推荐这么做，因为如果每一个组织或个人开发的程序都要添加自己的顶层菜单，那么会造成这个文件修改的混乱，更好的办法是自己创建一个.json的文件，并采用类似luci-base.js 的写法，比如我想创建一个名称是\u0026quot;HZX\u0026quot;的顶层菜单，那么可以添加一个文件\nluci-hzxtopmenu.js文件，文件内容如下：\n{ \u0026#34;admin/hzxtopmenu\u0026#34;: { //菜单对应在网页url中的地址后缀 \u0026#34;title\u0026#34;: \u0026#34;HZX\u0026#34;, //菜单栏上显示的名称 \u0026#34;order\u0026#34;: 80, //菜单栏的显示顺序（越大越在后面） \u0026#34;action\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;firstchild\u0026#34;, \u0026#34;recurse\u0026#34;: true } } } 只添加这一个文件并不能在菜单栏上显示 \u0026ldquo;HZX\u0026rdquo; ，我们需要在 \u0026ldquo;HZX\u0026rdquo; 下面添加一个子菜单选项，添加方式也是模仿已有app的写法，比如我们创建一个luci-app-goshadowsock2.json的文件，文件内容如下：\n{ \u0026#34;admin/hzxtopmenu/goshadowsocks2\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;GoShadowsocks2\u0026#34;, \u0026#34;order\u0026#34;: 10, \u0026#34;action\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;view\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;goshadowsocks2/overview\u0026#34; } } } 这样就可以在HZX菜单项的下面添加一个叫GoShadowsocks2的子菜单项，并且点击它之后的响应转到 /www/luci-static/resources/view/goshadowsocks2/overview.js 文件中去处理，后续要做的事情就是使用JavaScript脚本完善用户点击的响应。\n下图是添加这些文件后的效果\n","description":"","id":19,"section":"posts","tags":null,"title":"OpenWRT-19.07Luci编辑菜单方法","uri":"https://fanhestyle.github.io/posts/edit_menu_openwrt19.07/"},{"content":"1. 简介 OpenWRT19.07的一个重大的改动是将之前OpenWRT的Luci框架做了比较大的调整，最主要集中在将Luci的渲染方式从之前的服务端渲染模式调整到客户端的渲染模式。据OpenWRT官方说这种改动可以提升默写老旧设备的性能，将渲染网页的工作从路由器转移到用户的客户端设备。\n由于OpenWRT中luci-app非常众多，在本文写作时（最新版本是19.07.7）官方feeds中的luci-application仍然只改写了一小部分，后续估计官方会持续推进。鉴于目前19.07版本处于一种新旧方式过渡的阶段，大量老的使用lua编写的app尚未完全移植，因此如果发现老的app在19.07上运行异常（大部分都是由于cbi.lua造成的），官方给出了一些建议，包括：\n安装luci-compat包（提供老代码的兼容方式运行） 如果页面加载缓慢，可以考虑安装 uhttpd-mod-ubus 页面加载缓慢或修改设置之后，建议重新打开浏览器标签页（或者重启浏览器） 以下我们对 19.07前后两种不同方式的luci-app开发作一个比较，挑选18.06（19.07的上一个稳定发行版）和19.07进行对比分析\n2. 18.06的luci-app风格 2.1 luci-app开发的主要方式 主要是使用openwrt提供的框架，使用lua语言进行开发，采用MVC的架构方式，在 /usr/lib/lua/luci 目录中提供有 model、controller和view几个目录，在controller目录中通过编写lua文件，生成网页上的界面菜单并且指定如何处理点击菜单之后的响应。\n响应主要通过3种方式提供：\n（1）直接调用函数的方式，比如下面的示例展示了如何调用函数响应\nmodule(\u0026#34;luci.controller.myapp.mymodule\u0026#34;, package.seeall) function index() entry({\u0026#34;click\u0026#34;, \u0026#34;here\u0026#34;, \u0026#34;now\u0026#34;}, call(\u0026#34;action_tryme\u0026#34;), \u0026#34;Click here\u0026#34;, 10).dependent=false end function action_tryme() luci.http.prepare_content(\u0026#34;text/plain\u0026#34;) luci.http.write(\u0026#34;Haha, rebooting now...\u0026#34;) luci.sys.reboot() end 再我们点击某个菜单项时，这个菜单会调用action_tryme函数\n（2）通过调用一个html页面来响应\nentry({\u0026#34;my\u0026#34;, \u0026#34;new\u0026#34;, \u0026#34;template\u0026#34;}, template(\u0026#34;myapp-mymodule/helloworld\u0026#34;), \u0026#34;Hello world\u0026#34;, 20).dependent=false 代码会调用 /usr/lib/lua/luci/view/myapp-mymodule/helloworld.htm这个页面来响应用户的点击\n（3）通过CBI的方式来响应\n这种方式也是用的比较多的一种方式，它通过编写一个lua文件来生成一个网页（包含大量的网页中控件），这些控件对应着lua中的一些类型，并且这些类型直接和uci的配置文件绑定，示例如下：\nm = Map(\u0026#34;network\u0026#34;, \u0026#34;Network\u0026#34;) -- 对应着一个配置文件 /etc/config/network s = m:section(TypedSection, \u0026#34;interface\u0026#34;, \u0026#34;Interfaces\u0026#34;) -- s对应着network这个文件中的某一个配置块 s.addremove = true -- Allow the user to create and remove the interfaces function s:filter(value) return value ~= \u0026#34;loopback\u0026#34; and value -- Don\u0026#39;t touch loopback end s:depends(\u0026#34;proto\u0026#34;, \u0026#34;static\u0026#34;) -- Only show those with \u0026#34;static\u0026#34; s:depends(\u0026#34;proto\u0026#34;, \u0026#34;dhcp\u0026#34;) -- or \u0026#34;dhcp\u0026#34; as protocol and leave PPPoE and PPTP alone ... gw = s:option(Value, \u0026#34;gateway\u0026#34;, \u0026#34;Gateway\u0026#34;) gw:depends(\u0026#34;proto\u0026#34;, \u0026#34;static\u0026#34;) gw.rmempty = true -- Remove entry if it is empty return m -- 返回配置 当用户进行操作之后，它会把用户的操作对应到uci文件中的具体选项中，在保存的时候写入到配置文件中\n2.1 lua-app安装包的目录结构 老版本的luci-app的目录结构如下图所示：\n/ ├── etc/ │ ├── config/ │ │ └── shadowsocks // UCI 配置文件 │ │── init.d/ │ │ └── shadowsocks // init 脚本 │ └── uci-defaults/ │ └── luci-shadowsocks // uci-defaults 脚本 └── usr/ ├── bin/ │ └── ss-rules // 生成代理转发规则的脚本 └── lib/ └── lua/ └── luci/ // LuCI 部分 ├── controller/ │ └── shadowsocks.lua // LuCI 菜单配置 ├── i18n/ // LuCI 语言文件目录 │ └── shadowsocks.zh-cn.lmo └── model/ └── cbi/ └── shadowsocks/ ├── general.lua // LuCI 基本设置 ├── servers.lua // LuCI 服务器列表 ├── servers-details.lua // LuCI 服务器编辑 └── access-control.lua // LuCI 访问控制 这是一个luci-app ipk包内的文件结构，这些文件会被拷贝到OpenWRT系统中对应的位置，可以看到主题的交互文件就是在/usr/lib/lua/luci的model、controller目录中。除此之外还需要搭配一些配置文件、应用程序的启动初始化脚本、翻译文件，构成整个应用程序。\n3. 19.07的luci-app风格 新的luci-app把之前的模式进行了非常多的修改，首先一个最主要的改动就是减少了大量的lua代码，新的luci-app采用的是Javascript进行开发，并且页面基本上都是使用网页的方式来呈现（也就是直接编写html的文档，有点类似于18.06响应模式的第2种）\n新的luci-app包的文件结构如下：\nopenwrt ┕feeds ┕luci ┕applications ┕luci-app-name #界面程序的主目录 ┕htdocs ┊ ┕luci-static ┊ ┕resources ┊ ┕view ┊ ┕name.js # JavaScript 脚本界面文件。 ┕po ┊ ┕zh_Hans # 此目录名称对应简体中文。 ┊ ┕name.po # 界面语言翻译文件。 ┕root ┊ ┕etc ┊ ┊ ┕uci-defaults ┊ ┊ ┕luci-app-name # 软件安装完毕后默认执行的脚本（一次性脚本），可选。 ┊ ┕usr ┊ ┕share ┊ ┕luci ┊ ┊ ┕menu.d ┊ ┊ ┕luci-app-name.json # 界面菜单，在系统菜单中的名称、顺序等。 ┊ ┕rpcd ┊ ┕acl.d ┊ ┕luci-app-name.json # 权限控制文件，管控界面能执行的各类操作。 ┕Makefile # 编译文件。 下面这个链接给出了一个移植到新版本的luci-app程序相对于老版本的修改内容：\nluci-app-minidlna的改动 https://github.com/openwrt/luci/commit/9ae591b38fedf16c3e5c97350b7182c5e28ed71f#diff-27855472049b664538cca7ef50c43df8\n4. 参考资料 1.OpenWrt 19.07.0 - First Stable Release - 6 January 2020\n2. OpenWrt达人教程之开发人员入门指南\n3. OpenWRT18.06 IPK的目录结构\n","description":"","id":20,"section":"posts","tags":null,"title":"OpenWRT 19.07 Luci框架的改变","uri":"https://fanhestyle.github.io/posts/openwrt_19.07_luci_changes/"},{"content":"辗转几次还是回到这里，开始安心写作吧！\n","description":"","id":21,"section":"posts","tags":null,"title":"转圈圈","uri":"https://fanhestyle.github.io/posts/my-first-post/"}]